import streamlit as st
import pandas as pd
import requests
from bs4 import BeautifulSoup
import base64
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np
import streamlit.components.v1 as components
import plotly.express as px
import plotly.graph_objects as go
from datetime import datetime
import matplotlib as mp
import re
import os
import time

# Palette de couleurs
COLOR_PRIMARY = "#1976D2"
COLOR_BG = "#F4F7FA"
COLOR_ACCENT = "#FFB300"
COLOR_SUCCESS = "#43A047"
COLOR_ERROR = "#E53935"
COLOR_TEXT = "#222C36"
COLOR_TEXT_SECONDARY = "#5A7184"

# Configuration de la page
st.set_page_config(
    page_title="Analyse & Scraping CoinAfrique",
    page_icon="üìà",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Titre principal avec style
st.markdown(f"""
    <h1 style='text-align: center; color: {COLOR_PRIMARY}; font-size: 3rem; margin-bottom: 0;'>
        üìà Analyse et Scraping CoinAfrique
    </h1>
    <p style='text-align: center; color: {COLOR_TEXT_SECONDARY}; font-size: 1.2rem; margin-bottom: 2rem;'>
        Collecte, nettoyage et visualisation de donn√©es des annonces CoinAfrique S√©n√©gal
    </p>
""", unsafe_allow_html=True)

# Description de l'app
st.markdown(f"""
    <div style='background-color: {COLOR_BG}; padding: 1rem; border-radius: 10px; margin: 1rem 0;'>
        <p>
            Fonctionnalit√©s‚ÄØ:
            <ul>
                <li>üßπ Scraping nettoy√© (BeautifulSoup)</li>
                <li>üï∏Ô∏è Scraping brut (Web Scraper)</li>
                <li>üíæ T√©l√©chargement de CSV</li>
                <li>üìà Dashboard interactif</li>
                <li>üó®Ô∏è Formulaire d‚Äô√©valuation</li>
            </ul>
            <br>Sources‚ÄØ: <a href="https://sn.coinafrique.com/">Coinafrique S√©n√©gal</a>
        </p>
    </div>
""", unsafe_allow_html=True)

# Fonction de scraping avec BeautifulSoup (avec nettoyage)
def scrape_with_beautifulsoup(url_base, category_name, pages, clean_data=True):
    """Scraper avec BeautifulSoup et nettoyage optionnel"""
    data = []
    
    # Cr√©er une barre de progression
    progress_bar = st.progress(0)
    status_text = st.empty()
    
    for page in range(1, pages + 1):
        status_text.text(f'Scraping page {page}/{pages} - {category_name}...')
        progress_bar.progress(page / pages)
        
        url = f"{url_base}?page={page}"
        
        try:
            # Ajouter un d√©lai pour √©viter de surcharger le serveur
            time.sleep(1)
            
            headers = {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
            }
            response = requests.get(url, headers=headers, timeout=10)
            response.raise_for_status()
            
            soup = BeautifulSoup(response.text, 'html.parser')
            annonces = soup.find_all('div', class_='ad__card')
            
            for annonce in annonces:
                try:
                    # Extraire le type (v√™tement ou chaussure)
                    type_element = annonce.find('p', class_='ad__card-description')
                    type_item = type_element.get_text(strip=True) if type_element else "Non sp√©cifi√©"
                    
                    # Extraire le prix
                    prix_element = annonce.find('p', class_='ad__card-price')
                    prix = prix_element.get_text(strip=True) if prix_element else "Prix non sp√©cifi√©"
                    
                    # Extraire l'adresse
                    location_element = annonce.find('p', class_='ad__card-location')
                    if location_element:
                        span_element = location_element.find('span')
                        adresse = span_element.get_text(strip=True) if span_element else "Adresse non sp√©cifi√©e"
                    else:
                        adresse = "Adresse non sp√©cifi√©e"
                    
                    # Extraire le lien de l'image
                    img_element = annonce.find('img', class_='ad__card-img')
                    image_lien = img_element['src'] if img_element and 'src' in img_element.attrs else "Image non disponible"
                    
                    data.append({
                        "categorie": category_name,
                        "type": type_item,
                        "prix": prix,
                        "adresse": adresse,
                        "image_lien": image_lien
                    })
                    
                except Exception as e:
                    continue
                    
        except requests.exceptions.RequestException as e:
            st.error(f"Erreur lors du scraping de la page {page}: {str(e)}")
            continue
        except Exception as e:
            st.error(f"Erreur inattendue page {page}: {str(e)}")
            continue
    
    progress_bar.empty()
    status_text.empty()
    
    df = pd.DataFrame(data)
    
    # Nettoyer les donn√©es si demand√©
    if clean_data and not df.empty:
        df = clean_scraped_data(df)
    
    return df

# Fonction de nettoyage des donn√©es
def clean_scraped_data(df):
    """Nettoyer les donn√©es scrap√©es avec v√©rification des colonnes"""
    if df.empty:
        return df

    df_clean = df.copy()

    if 'prix' in df_clean.columns:
        df_clean['prix_brut'] = df_clean['prix']
        df_clean['prix_numerique'] = df_clean['prix'].str.replace(r'[^\d]', '', regex=True)
        df_clean['prix_numerique'] = pd.to_numeric(df_clean['prix_numerique'], errors='coerce')
        df_clean['a_prix'] = df_clean['prix_numerique'].notna()
    else:
        df_clean['prix_brut'] = "Inconnu"
        df_clean['prix_numerique'] = np.nan
        df_clean['a_prix'] = False

    if 'adresse' in df_clean.columns:
        df_clean['adresse'] = df_clean['adresse'].str.strip().str.title()
    else:
        df_clean['adresse'] = "Adresse inconnue"

    if 'type' in df_clean.columns:
        df_clean['type'] = df_clean['type'].str.strip().str.title()
    else:
        df_clean['type'] = "Type inconnu"

    if 'image_lien' in df_clean.columns:
        df_clean['a_image'] = df_clean['image_lien'] != "Image non disponible"
    else:
        df_clean['a_image'] = False

    df_clean = df_clean.drop_duplicates(subset=['type', 'prix_brut', 'adresse'])

    return df_clean


# Fonction pour convertir le DataFrame en CSV
def convert_df_to_csv(df):
    """Convertir DataFrame en CSV"""
    return df.to_csv(index=False).encode('utf-8')

# Fonction pour sauvegarder les donn√©es
def save_data_to_csv(df, filename):
    """Sauvegarder les donn√©es dans un fichier CSV"""
    if not df.empty:
        df.to_csv(filename, index=False)
        return True
    return False

# Fonction pour charger les donn√©es depuis un fichier CSV
def load_data_from_csv(filepath):
    """Charger les donn√©es depuis un fichier CSV avec gestion des erreurs"""
    try:
        if os.path.exists(filepath):
            return pd.read_csv(filepath, encoding='utf-8')
        else:
            st.warning(f"üìÇ Fichier introuvable : {filepath}")
            return pd.DataFrame()
    except pd.errors.ParserError as e:
        st.error(f"‚ùå Erreur de format dans {filepath} : {str(e)}")
        return pd.DataFrame()
    except Exception as e:
        st.error(f"‚ùå Erreur inconnue lors du chargement de {filepath} : {str(e)}")
        return pd.DataFrame()


# Fonction pour cr√©er le dashboard
def create_dashboard(df):
    """Cr√©er un dashboard interactif"""
    if df.empty:
        st.warning('‚ö†Ô∏è Aucune donn√©e disponible pour le dashboard.')
        return
    
    st.markdown("""
        <h2 style='text-align: center; color: #2E86AB; margin: 2rem 0;'>
            üìä DASHBOARD ANALYTIQUE
        </h2>
    """, unsafe_allow_html=True)
    
    # M√©triques principales
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric("üìù Total articles", len(df))
    
    with col2:
        if 'prix_numerique' in df.columns:
            prix_valides = df['prix_numerique'].dropna()
            if not prix_valides.empty:
                prix_moyen = prix_valides.mean()
                st.metric("üí∞ Prix moyen", f"{prix_moyen:,.0f} FCFA")
            else:
                st.metric("üí∞ Prix moyen", "N/A")
        else:
            st.metric("üí∞ Prix moyen", "N/A")
    
    with col3:
        nb_categories = df['categorie'].nunique()
        st.metric("üè∑Ô∏è Cat√©gories", nb_categories)
    
    with col4:
        nb_villes = df['adresse'].nunique()
        st.metric("üèôÔ∏è Villes", nb_villes)
    
    # Graphiques
    col1, col2 = st.columns(2)
    
    with col1:
        # Distribution par cat√©gorie
        fig_cat = px.pie(
            df, 
            names='categorie', 
            title='Distribution par Cat√©gorie',
            color_discrete_sequence=px.colors.qualitative.Set3
        )
        fig_cat.update_layout(height=400)
        st.plotly_chart(fig_cat, use_container_width=True)
    
    with col2:
        # Top 10 des villes
        top_villes = df['adresse'].value_counts().head(10)
        fig_villes = px.bar(
            x=top_villes.values,
            y=top_villes.index,
            orientation='h',
            title='Top 10 des Villes',
            labels={'x': 'Nombre d\'articles', 'y': 'Ville'}
        )
        fig_villes.update_layout(height=400)
        st.plotly_chart(fig_villes, use_container_width=True)
    
    # Analyse des prix si disponible
    if 'prix_numerique' in df.columns:
        prix_valides = df.dropna(subset=['prix_numerique'])
        if not prix_valides.empty:
            col1, col2 = st.columns(2)
            
            with col1:
                # Distribution des prix par cat√©gorie
                fig_prix = px.box(
                    prix_valides, 
                    x='categorie', 
                    y='prix_numerique',
                    title='Distribution des Prix par Cat√©gorie'
                )
                fig_prix.update_layout(height=400)
                fig_prix.update_xaxes(tickangle=45)
                st.plotly_chart(fig_prix, use_container_width=True)
            
            with col2:
                # Histogramme des prix
                fig_hist = px.histogram(
                    prix_valides, 
                    x='prix_numerique',
                    title='Distribution des Prix',
                    nbins=30
                )
                fig_hist.update_layout(height=400)
                st.plotly_chart(fig_hist, use_container_width=True)

# Sidebar pour les param√®tres
st.sidebar.header('üîß Param√®tres de Configuration')
st.sidebar.markdown("---")

# S√©lection du nombre de pages
pages = st.sidebar.selectbox(
    'üìÑ Nombre de pages √† scraper',
    options=list(range(1, 21)),
    index=2,  # Par d√©faut 3 pages
    help="S√©lectionnez le nombre de pages √† scraper pour chaque cat√©gorie"
)

# Options principales
choices = st.sidebar.selectbox(
    'üéØ Choisissez une option',
    options=[
        'Scraper avec BeautifulSoup (nettoyage)',
        'Scraper avec Web Scraper (donn√©es brutes)',
        'T√©l√©charger donn√©es pr√©-scrap√©es',
        'Dashboard des donn√©es nettoy√©es',
        'Formulaire d\'√©valuation'
    ],
    help="S√©lectionnez l'action que vous souhaitez effectuer"
)

st.sidebar.markdown("---")

# Configuration des chemins pour les fichiers pr√©-scrap√©s
if choices == 'T√©l√©charger donn√©es pr√©-scrap√©es':
    st.sidebar.subheader('üìÅ Chemins des fichiers CSV')
    
    vetements_homme_path = st.sidebar.text_input(
        'V√™tements Homme CSV',
        value='data/vetements_homme.csv',
        help='Chemin vers le fichier CSV des v√™tements homme'
    )
    
    chaussures_homme_path = st.sidebar.text_input(
        'Chaussures Homme CSV',
        value='data/chaussures_homme.csv',
        help='Chemin vers le fichier CSV des chaussures homme'
    )
    
    vetements_enfants_path = st.sidebar.text_input(
        'V√™tements Enfants CSV',
        value='data/vetements_enfants.csv',
        help='Chemin vers le fichier CSV des v√™tements enfants'
    )
    
    chaussures_enfants_path = st.sidebar.text_input(
        'Chaussures Enfants CSV',
        value='data/chaussures_enfants.csv',
        help='Chemin vers le fichier CSV des chaussures enfants'
    )

st.sidebar.markdown("---")
st.sidebar.markdown("""
    <div style='text-align: center; color: #666; font-size: 0.8rem;'>
        <p>Emmanuel ZAGRE</p>
        <p>¬© 2025 Analyse & Scraping CoinAfrique</p>
    </div>
""", unsafe_allow_html=True)

# Interface principale
if choices == 'Scraper avec BeautifulSoup (nettoyage)':
    st.markdown("""
        <div style='background-color: #e8f4f8; padding: 1rem; border-radius: 10px; margin: 1rem 0;'>
            <h3 style='color: #2E86AB; margin-bottom: 1rem;'>üîÑ Scraping avec BeautifulSoup et nettoyage</h3>
            <p>Cliquez sur les boutons ci-dessous pour scraper et nettoyer les donn√©es en temps r√©el depuis Coinafrique.</p>
        </div>
    """, unsafe_allow_html=True)
    
    # URLs de base pour chaque cat√©gorie
    urls = {
        'V√™tements Homme': 'https://sn.coinafrique.com/categorie/vetements-homme',
        'Chaussures Homme': 'https://sn.coinafrique.com/categorie/chaussures-homme',
        'V√™tements Enfants': 'https://sn.coinafrique.com/categorie/vetements-enfants',
        'Chaussures Enfants': 'https://sn.coinafrique.com/categorie/chaussures-enfants'
    }
    
    # Cr√©er les colonnes pour les boutons
    col1, col2 = st.columns(2)
    
    with col1:
        # V√™tements Homme
        st.markdown("### üëî V√™tements Homme")
        if st.button('üöÄ Scraper V√™tements Homme', key='scrape_vh', use_container_width=True):
            with st.spinner('Scraping en cours...'):
                df = scrape_with_beautifulsoup(urls['V√™tements Homme'], 'V√™tements Homme', pages, clean_data=True)
                if not df.empty:
                    st.success(f'‚úÖ {len(df)} articles r√©cup√©r√©s et nettoy√©s!')
                    st.info(f'üìä Dimensions: {df.shape[0]} lignes et {df.shape[1]} colonnes')
                    st.dataframe(df.head(), use_container_width=True)
                    
                    # Sauvegarder automatiquement
                    if save_data_to_csv(df, 'vetements_homme_cleaned.csv'):
                        st.success('üíæ Donn√©es sauvegard√©es dans vetements_homme_cleaned.csv')
                    
                    # Bouton de t√©l√©chargement
                    csv = convert_df_to_csv(df)
                    st.download_button(
                        label="üì• T√©l√©charger CSV",
                        data=csv,
                        file_name=f'vetements_homme_cleaned_{datetime.now().strftime("%Y%m%d_%H%M%S")}.csv',
                        mime='text/csv',
                        key='download_vh'
                    )
                else:
                    st.warning('‚ö†Ô∏è Aucune donn√©e r√©cup√©r√©e.')
        
        # V√™tements Enfants
        st.markdown("### üë∂ V√™tements Enfants")
        if st.button('üöÄ Scraper V√™tements Enfants', key='scrape_ve', use_container_width=True):
            with st.spinner('Scraping en cours...'):
                df = scrape_with_beautifulsoup(urls['V√™tements Enfants'], 'V√™tements Enfants', pages, clean_data=True)
                if not df.empty:
                    st.success(f'‚úÖ {len(df)} articles r√©cup√©r√©s et nettoy√©s!')
                    st.info(f'üìä Dimensions: {df.shape[0]} lignes et {df.shape[1]} colonnes')
                    st.dataframe(df.head(), use_container_width=True)
                    
                    # Sauvegarder automatiquement
                    if save_data_to_csv(df, 'vetements_enfants_cleaned.csv'):
                        st.success('üíæ Donn√©es sauvegard√©es dans vetements_enfants_cleaned.csv')
                    
                    # Bouton de t√©l√©chargement
                    csv = convert_df_to_csv(df)
                    st.download_button(
                        label="üì• T√©l√©charger CSV",
                        data=csv,
                        file_name=f'vetements_enfants_cleaned_{datetime.now().strftime("%Y%m%d_%H%M%S")}.csv',
                        mime='text/csv',
                        key='download_ve'
                    )
                else:
                    st.warning('‚ö†Ô∏è Aucune donn√©e r√©cup√©r√©e.')
    
    with col2:
        # Chaussures Homme
        st.markdown("### üëû Chaussures Homme")
        if st.button('üöÄ Scraper Chaussures Homme', key='scrape_ch', use_container_width=True):
            with st.spinner('Scraping en cours...'):
                df = scrape_with_beautifulsoup(urls['Chaussures Homme'], 'Chaussures Homme', pages, clean_data=True)
                if not df.empty:
                    st.success(f'‚úÖ {len(df)} articles r√©cup√©r√©s et nettoy√©s!')
                    st.info(f'üìä Dimensions: {df.shape[0]} lignes et {df.shape[1]} colonnes')
                    st.dataframe(df.head(), use_container_width=True)
                    
                    # Sauvegarder automatiquement
                    if save_data_to_csv(df, 'chaussures_homme_cleaned.csv'):
                        st.success('üíæ Donn√©es sauvegard√©es dans chaussures_homme_cleaned.csv')
                    
                    # Bouton de t√©l√©chargement
                    csv = convert_df_to_csv(df)
                    st.download_button(
                        label="üì• T√©l√©charger CSV",
                        data=csv,
                        file_name=f'chaussures_homme_cleaned_{datetime.now().strftime("%Y%m%d_%H%M%S")}.csv',
                        mime='text/csv',
                        key='download_ch'
                    )
                else:
                    st.warning('‚ö†Ô∏è Aucune donn√©e r√©cup√©r√©e.')
        
        # Chaussures Enfants
        st.markdown("### üëü Chaussures Enfants")
        if st.button('üöÄ Scraper Chaussures Enfants', key='scrape_ce', use_container_width=True):
            with st.spinner('Scraping en cours...'):
                df = scrape_with_beautifulsoup(urls['Chaussures Enfants'], 'Chaussures Enfants', pages, clean_data=True)
                if not df.empty:
                    st.success(f'‚úÖ {len(df)} articles r√©cup√©r√©s et nettoy√©s!')
                    st.info(f'üìä Dimensions: {df.shape[0]} lignes et {df.shape[1]} colonnes')
                    st.dataframe(df.head(), use_container_width=True)
                    
                    # Sauvegarder automatiquement
                    if save_data_to_csv(df, 'chaussures_enfants_cleaned.csv'):
                        st.success('üíæ Donn√©es sauvegard√©es dans chaussures_enfants_cleaned.csv')
                    
                    # Bouton de t√©l√©chargement
                    csv = convert_df_to_csv(df)
                    st.download_button(
                        label="üì• T√©l√©charger CSV",
                        data=csv,
                        file_name=f'chaussures_enfants_cleaned_{datetime.now().strftime("%Y%m%d_%H%M%S")}.csv',
                        mime='text/csv',
                        key='download_ce'
                    )
                else:
                    st.warning('‚ö†Ô∏è Aucune donn√©e r√©cup√©r√©e.')

elif choices == 'Scraper avec Web Scraper (donn√©es brutes)':
    st.markdown("""
        <div style='background-color: #fff3cd; padding: 1rem; border-radius: 10px; margin: 1rem 0;'>
            <h3 style='color: #856404; margin-bottom: 1rem;'>üîÑ Scraping avec Web Scraper (donn√©es brutes)</h3>
            <p>Cliquez sur les boutons ci-dessous pour scraper les donn√©es brutes (non nettoy√©es) depuis Coinafrique.</p>
        </div>
    """, unsafe_allow_html=True)
    
    # URLs de base pour chaque cat√©gorie
    urls = {
        'V√™tements Homme': 'https://sn.coinafrique.com/categorie/vetements-homme',
        'Chaussures Homme': 'https://sn.coinafrique.com/categorie/chaussures-homme',
        'V√™tements Enfants': 'https://sn.coinafrique.com/categorie/vetements-enfants',
        'Chaussures Enfants': 'https://sn.coinafrique.com/categorie/chaussures-enfants'
    }
    
    # Cr√©er les colonnes pour les boutons
    col1, col2 = st.columns(2)
    
    with col1:
        # V√™tements Homme
        st.markdown("### üëî V√™tements Homme")
        if st.button('üöÄ Scraper V√™tements Homme (Brut)', key='scrape_vh_raw', use_container_width=True):
            with st.spinner('Scraping en cours...'):
                df = scrape_with_beautifulsoup(urls['V√™tements Homme'], 'V√™tements Homme', pages, clean_data=False)
                if not df.empty:
                    st.success(f'‚úÖ {len(df)} articles r√©cup√©r√©s (donn√©es brutes)!')
                    st.info(f'üìä Dimensions: {df.shape[0]} lignes et {df.shape[1]} colonnes')
                    st.dataframe(df.head(), use_container_width=True)
                    
                    # Sauvegarder automatiquement
                    if save_data_to_csv(df, 'vetements_homme_raw.csv'):
                        st.success('üíæ Donn√©es sauvegard√©es dans vetements_homme_raw.csv')
                    
                    # Bouton de t√©l√©chargement
                    csv = convert_df_to_csv(df)
                    st.download_button(
                        label="üì• T√©l√©charger CSV",
                        data=csv,
                        file_name=f'vetements_homme_raw_{datetime.now().strftime("%Y%m%d_%H%M%S")}.csv',
                        mime='text/csv',
                        key='download_vh_raw'
                    )
                else:
                    st.warning('‚ö†Ô∏è Aucune donn√©e r√©cup√©r√©e.')
        
        # V√™tements Enfants
        st.markdown("### üë∂ V√™tements Enfants")
        if st.button('üöÄ Scraper V√™tements Enfants (Brut)', key='scrape_ve_raw', use_container_width=True):
            with st.spinner('Scraping en cours...'):
                df = scrape_with_beautifulsoup(urls['V√™tements Enfants'], 'V√™tements Enfants', pages, clean_data=False)
                if not df.empty:
                    st.success(f'‚úÖ {len(df)} articles r√©cup√©r√©s (donn√©es brutes)!')
                    st.info(f'üìä Dimensions: {df.shape[0]} lignes et {df.shape[1]} colonnes')
                    st.dataframe(df.head(), use_container_width=True)
                    
                    # Sauvegarder automatiquement
                    if save_data_to_csv(df, 'vetements_enfants_raw.csv'):
                        st.success('üíæ Donn√©es sauvegard√©es dans vetements_enfants_raw.csv')
                    
                    # Bouton de t√©l√©chargement
                    csv = convert_df_to_csv(df)
                    st.download_button(
                        label="üì• T√©l√©charger CSV",
                        data=csv,
                        file_name=f'vetements_enfants_raw_{datetime.now().strftime("%Y%m%d_%H%M%S")}.csv',
                        mime='text/csv',
                        key='download_ve_raw'
                    )
                else:
                    st.warning('‚ö†Ô∏è Aucune donn√©e r√©cup√©r√©e.')
    
    with col2:
        # Chaussures Homme
        st.markdown("### üëû Chaussures Homme")
        if st.button('üöÄ Scraper Chaussures Homme (Brut)', key='scrape_ch_raw', use_container_width=True):
            with st.spinner('Scraping en cours...'):
                df = scrape_with_beautifulsoup(urls['Chaussures Homme'], 'Chaussures Homme', pages, clean_data=False)
                if not df.empty:
                    st.success(f'‚úÖ {len(df)} articles r√©cup√©r√©s (donn√©es brutes)!')
                    st.info(f'üìä Dimensions: {df.shape[0]} lignes et {df.shape[1]} colonnes')
                    st.dataframe(df.head(), use_container_width=True)
                    
                    # Sauvegarder automatiquement
                    if save_data_to_csv(df, 'chaussures_homme_raw.csv'):
                        st.success('üíæ Donn√©es sauvegard√©es dans chaussures_homme_raw.csv')
                    
                    # Bouton de t√©l√©chargement
                    csv = convert_df_to_csv(df)
                    st.download_button(
                        label="üì• T√©l√©charger CSV",
                        data=csv,
                        file_name=f'chaussures_homme_raw_{datetime.now().strftime("%Y%m%d_%H%M%S")}.csv',
                        mime='text/csv',
                        key='download_ch_raw'
                    )
                else:
                    st.warning('‚ö†Ô∏è Aucune donn√©e r√©cup√©r√©e.')
        
        # Chaussures Enfants
        st.markdown("### üëü Chaussures Enfants")
        if st.button('üöÄ Scraper Chaussures Enfants (Brut)', key='scrape_ce_raw', use_container_width=True):
            with st.spinner('Scraping en cours...'):
                df = scrape_with_beautifulsoup(urls['Chaussures Enfants'], 'Chaussures Enfants', pages, clean_data=False)
                if not df.empty:
                    st.success(f'‚úÖ {len(df)} articles r√©cup√©r√©s (donn√©es brutes)!')
                    st.info(f'üìä Dimensions: {df.shape[0]} lignes et {df.shape[1]} colonnes')
                    st.dataframe(df.head(), use_container_width=True)
                    
                    # Sauvegarder automatiquement
                    if save_data_to_csv(df, 'chaussures_enfants_raw.csv'):
                        st.success('üíæ Donn√©es sauvegard√©es dans chaussures_enfants_raw.csv')
                    
                    # Bouton de t√©l√©chargement
                    csv = convert_df_to_csv(df)
                    st.download_button(
                        label="üì• T√©l√©charger CSV",
                        data=csv,
                        file_name=f'chaussures_enfants_raw_{datetime.now().strftime("%Y%m%d_%H%M%S")}.csv',
                        mime='text/csv',
                        key='download_ce_raw'
                    )
                else:
                    st.warning('‚ö†Ô∏è Aucune donn√©e r√©cup√©r√©e.')

elif choices == 'T√©l√©charger donn√©es pr√©-scrap√©es':
    st.markdown("""
        <div style='background-color: #d1ecf1; padding: 1rem; border-radius: 10px; margin: 1rem 0;'>
            <h3 style='color: #0c5460; margin-bottom: 1rem;'>üì• T√©l√©charger donn√©es pr√©-scrap√©es</h3>
            <p>Chargez et t√©l√©chargez les donn√©es qui ont √©t√© pr√©-scrap√©es et sauvegard√©es dans des fichiers CSV.</p>
        </div>
    """, unsafe_allow_html=True)
    
    # Cr√©er les colonnes pour les boutons
    col1, col2 = st.columns(2)
    
    with col1:
        # V√™tements Homme
        st.markdown("### üëî V√™tements Homme")
        if st.button('üìÇ Charger V√™tements Homme', key='load_vh', use_container_width=True):
            df = load_data_from_csv(vetements_homme_path)
            if not df.empty:
                st.success(f'‚úÖ {len(df)} articles charg√©s depuis {vetements_homme_path}!')
                st.info(f'üìä Dimensions: {df.shape[0]} lignes et {df.shape[1]} colonnes')
                st.dataframe(df.head(10), use_container_width=True)
                
                # Bouton de t√©l√©chargement
                csv = convert_df_to_csv(df)
                st.download_button(
                    label="üì• T√©l√©charger CSV",
                    data=csv,
                    file_name=f'vetements_homme_prescraped_{datetime.now().strftime("%Y%m%d_%H%M%S")}.csv',
                    mime='text/csv',
                    key='download_vh_pre'
                )
            else:
                st.warning('‚ö†Ô∏è Aucune donn√©e trouv√©e ou fichier inexistant.')
        
        # V√™tements Enfants
        st.markdown("### üë∂ V√™tements Enfants")
        if st.button('üìÇ Charger V√™tements Enfants', key='load_ve', use_container_width=True):
            df = load_data_from_csv(vetements_enfants_path)
            if not df.empty:
                st.success(f'‚úÖ {len(df)} articles charg√©s depuis {vetements_enfants_path}!')
                st.info(f'üìä Dimensions: {df.shape[0]} lignes et {df.shape[1]} colonnes')
                st.dataframe(df.head(10), use_container_width=True)
                
                # Bouton de t√©l√©chargement
                csv = convert_df_to_csv(df)
                st.download_button(
                    label="üì• T√©l√©charger CSV",
                    data=csv,
                    file_name=f'vetements_enfants_prescraped_{datetime.now().strftime("%Y%m%d_%H%M%S")}.csv',
                    mime='text/csv',
                    key='download_ve_pre'
                )
            else:
                st.warning('‚ö†Ô∏è Aucune donn√©e trouv√©e ou fichier inexistant.')
    
    with col2:
        # Chaussures Homme
        st.markdown("### üëû Chaussures Homme")
        if st.button('üìÇ Charger Chaussures Homme', key='load_ch', use_container_width=True):
            df = load_data_from_csv(chaussures_homme_path)
            if not df.empty:
                st.success(f'‚úÖ {len(df)} articles charg√©s depuis {chaussures_homme_path}!')
                st.info(f'üìä Dimensions: {df.shape[0]} lignes et {df.shape[1]} colonnes')
                st.dataframe(df.head(10), use_container_width=True)
                
                # Bouton de t√©l√©chargement
                csv = convert_df_to_csv(df)
                st.download_button(
                    label="üì• T√©l√©charger CSV",
                    data=csv,
                    file_name=f'chaussures_homme_prescraped_{datetime.now().strftime("%Y%m%d_%H%M%S")}.csv',
                    mime='text/csv',
                    key='download_ch_pre'
                )
            else:
                st.warning('‚ö†Ô∏è Aucune donn√©e trouv√©e ou fichier inexistant.')
        
        # Chaussures Enfants
        st.markdown("### üëü Chaussures Enfants")
        if st.button('üìÇ Charger Chaussures Enfants', key='load_ce', use_container_width=True):
            df = load_data_from_csv(chaussures_enfants_path)
            if not df.empty:
                st.success(f'‚úÖ {len(df)} articles charg√©s depuis {chaussures_enfants_path}!')
                st.info(f'üìä Dimensions: {df.shape[0]} lignes et {df.shape[1]} colonnes')
                st.dataframe(df.head(10), use_container_width=True)
                
                # Bouton de t√©l√©chargement
                csv = convert_df_to_csv(df)
                st.download_button(
                    label="üì• T√©l√©charger CSV",
                    data=csv,
                    file_name=f'chaussures_enfants_prescraped_{datetime.now().strftime("%Y%m%d_%H%M%S")}.csv',
                    mime='text/csv',
                    key='download_ce_pre'
                )
            else:
                st.warning('‚ö†Ô∏è Aucune donn√©e trouv√©e ou fichier inexistant.')
    
    # Section pour charger tous les fichiers √† la fois
    st.markdown("---")
    st.markdown("### üìä Charger toutes les donn√©es")
    
    if st.button('üìÇ Charger toutes les cat√©gories', key='load_all', use_container_width=True):
        all_data = []
        paths = [
            (vetements_homme_path, 'V√™tements Homme'),
            (chaussures_homme_path, 'Chaussures Homme'),
            (vetements_enfants_path, 'V√™tements Enfants'),
            (chaussures_enfants_path, 'Chaussures Enfants')
        ]
        
        for path, category in paths:
            df = load_data_from_csv(path)
            if not df.empty:
                all_data.append(df)
                st.success(f'‚úÖ {category}: {len(df)} articles charg√©s')
            else:
                st.warning(f'‚ö†Ô∏è {category}: Aucune donn√©e trouv√©e')
        
        if all_data:
            combined_df = pd.concat(all_data, ignore_index=True)
            st.success(f'üéâ Total combin√©: {len(combined_df)} articles de {len(all_data)} cat√©gories')
            st.dataframe(combined_df.head(20), use_container_width=True)
            
            # Bouton de t√©l√©chargement pour toutes les donn√©es
            csv_all = convert_df_to_csv(combined_df)
            st.download_button(
                label="üì• T√©l√©charger toutes les donn√©es (CSV)",
                data=csv_all,
                file_name=f'coinafrique_all_data_{datetime.now().strftime("%Y%m%d_%H%M%S")}.csv',
                mime='text/csv',
                key='download_all_pre'
            )

elif choices == 'Dashboard des donn√©es nettoy√©es':
    st.markdown("""
        <div style='background-color: #d4edda; padding: 1rem; border-radius: 10px; margin: 1rem 0;'>
            <h3 style='color: #155724; margin-bottom: 1rem;'>üìä Dashboard des donn√©es nettoy√©es</h3>
            <p>Visualisez les donn√©es nettoy√©es sous forme de graphiques interactifs.</p>
        </div>
    """, unsafe_allow_html=True)
    
    # Option pour choisir la source des donn√©es
    data_source = st.selectbox(
        'üìÇ Choisir la source des donn√©es',
        options=[
            'Charger depuis fichiers CSV',
            'Utiliser donn√©es d\'exemple',
            'Combiner toutes les sources'
        ],
        help="S√©lectionnez la source des donn√©es pour le dashboard"
    )
    
    if data_source == 'Charger depuis fichiers CSV':
        st.markdown("### üìÅ S√©lectionner les fichiers √† analyser")
        
        # Checkboxes pour s√©lectionner les fichiers
        use_vh = st.checkbox('V√™tements Homme', value=True)
        use_ch = st.checkbox('Chaussures Homme', value=True)
        use_ve = st.checkbox('V√™tements Enfants', value=True)
        use_ce = st.checkbox('Chaussures Enfants', value=True)
        
        if st.button('üöÄ G√©n√©rer Dashboard', key='generate_dashboard'):
            dashboard_data = []
            
            if use_vh:
                df_vh = load_data_from_csv('data/vetements_homme.csv')
                if not df_vh.empty:
                    dashboard_data.append(df_vh)
            
            if use_ch:
                df_ch = load_data_from_csv('data/chaussures_homme.csv')
                if not df_ch.empty:
                    dashboard_data.append(df_ch)
            
            if use_ve:
                df_ve = load_data_from_csv('data/vetements_enfants.csv')
                if not df_ve.empty:
                    dashboard_data.append(df_ve)
            
            if use_ce:
                df_ce = load_data_from_csv('data/chaussures_enfants.csv')
                if not df_ce.empty:
                    dashboard_data.append(df_ce)
            
            if dashboard_data:
                combined_df = pd.concat(dashboard_data, ignore_index=True)
                # Nettoyer les donn√©es avant de cr√©er le dashboard
                cleaned_df = clean_scraped_data(combined_df)
                create_dashboard(cleaned_df)
            else:
                st.warning('‚ö†Ô∏è Aucune donn√©e trouv√©e dans les fichiers s√©lectionn√©s.')
    
    elif data_source == 'Utiliser donn√©es d\'exemple':
        # Cr√©er des donn√©es d'exemple r√©alistes
        sample_data = pd.DataFrame({
            'categorie': ['V√™tements Homme', 'Chaussures Homme', 'V√™tements Enfants', 'Chaussures Enfants'] * 50,
            'type': ['Chemise', 'Sneakers', 'T-shirt', 'Sandales'] * 50,
            'prix': ['15000 FCFA', '25000 FCFA', '8000 FCFA', '12000 FCFA'] * 50,
            'adresse': ['Dakar', 'Thi√®s', 'Kaolack', 'Saint-Louis', 'Ziguinchor'] * 40,
            'image_lien': ['https://example.com/img1.jpg'] * 200
        })
        
        # Ajouter de la variabilit√©
        np.random.seed(42)
        prix_variations = np.random.normal(1, 0.3, len(sample_data))
        sample_data['prix'] = sample_data['prix'].str.replace(r'[^\d]', '', regex=True).astype(int)
        sample_data['prix'] = (sample_data['prix'] * prix_variations).astype(int)
        sample_data['prix'] = sample_data['prix'].astype(str) + ' FCFA'
        
        cleaned_sample = clean_scraped_data(sample_data)
        create_dashboard(cleaned_sample)
    
    else:  # Combiner toutes les sources
        st.markdown("### üìä Dashboard combin√©")
        def create_dashboard(df):
            """Cr√©er un dashboard interactif adapt√© √† l'application CoinAfrique"""
            if df.empty:
                st.warning('‚ö†Ô∏è Aucune donn√©e disponible pour le dashboard.')
                return

            st.markdown("""
                <h2 style='text-align: center; color: #2E86AB; margin: 2rem 0;'>
                    üìä DASHBOARD ANALYTIQUE
                </h2>
            """, unsafe_allow_html=True)

            # üî¢ M√©triques principales
            col1, col2, col3, col4 = st.columns(4)

            with col1:
                st.metric("üìù Total articles", len(df))

            with col2:
                if 'prix_numerique' in df.columns and df['prix_numerique'].notna().any():
                    st.metric("üí∞ Prix moyen", f"{df['prix_numerique'].mean():,.0f} FCFA")
                else:
                    st.metric("üí∞ Prix moyen", "N/A")

            with col3:
                if 'categorie' in df.columns:
                    st.metric("üè∑Ô∏è Cat√©gories", df['categorie'].nunique())
                else:
                    st.metric("üè∑Ô∏è Cat√©gories", "N/A")

            with col4:
                if 'adresse' in df.columns:
                    st.metric("üèôÔ∏è Villes", df['adresse'].nunique())
                else:
                    st.metric("üèôÔ∏è Villes", "N/A")

            # üìà Graphiques
            col1, col2 = st.columns(2)

            with col1:
                if 'categorie' in df.columns:
                    fig_cat = px.pie(
                        df,
                        names='categorie',
                        title='R√©partition par cat√©gorie',
                        color_discrete_sequence=px.colors.qualitative.Set3
                    )
                    fig_cat.update_layout(height=400)
                    st.plotly_chart(fig_cat, use_container_width=True)

            with col2:
                if 'adresse' in df.columns:
                    top_villes = df['adresse'].value_counts().head(10)
                    fig_villes = px.bar(
                        x=top_villes.values,
                        y=top_villes.index,
                        orientation='h',
                        title='Top 10 des villes',
                        labels={'x': 'Nombre d\'articles', 'y': 'Ville'}
                    )
                    fig_villes.update_layout(height=400)
                    st.plotly_chart(fig_villes, use_container_width=True)

            # üìä Analyse des prix
            if 'prix_numerique' in df.columns and df['prix_numerique'].notna().any():
                prix_valides = df.dropna(subset=['prix_numerique'])

                col1, col2 = st.columns(2)

                with col1:
                    if 'categorie' in df.columns:
                        fig_box = px.box(
                            prix_valides,
                            x='categorie',
                            y='prix_numerique',
                            title='Distribution des prix par cat√©gorie'
                        )
                        fig_box.update_layout(height=400)
                        fig_box.update_xaxes(tickangle=45)
                        st.plotly_chart(fig_box, use_container_width=True)

                with col2:
                    fig_hist = px.histogram(
                        prix_valides,
                        x='prix_numerique',
                        nbins=30,
                        title='Distribution des prix'
                    )
                    fig_hist.update_layout(height=400)
                    st.plotly_chart(fig_hist, use_container_width=True)
            if all_sources:
                combined_df = pd.concat(all_sources, ignore_index=True).drop_duplicates()
                cleaned_df = clean_scraped_data(combined_df)

        if 'categorie' not in cleaned_df.columns:
            st.warning("‚ö†Ô∏è La colonne 'categorie' est absente. Le dashboard ne peut pas √™tre g√©n√©r√©.")
            st.dataframe(cleaned_df.head())
        else:
            create_dashboard(cleaned_df)  # 
            

            
            # Fichiers possibles
            base_path = "C:/Users/ZAGRE/OneDrive/Desktop/ZAGRE-Emmanuel-DC/data"

            possible_files = [
                (f"{base_path}/vetements_homme.csv", "V√™tements Homme"),
                (f"{base_path}/chaussures_homme.csv", "Chaussures Homme"),
                (f"{base_path}/vetements_enfants.csv", "V√™tements Enfants"),
                (f"{base_path}/chaussures_enfants.csv", "Chaussures Enfants"),
                (f"{base_path}/vetements_homme_cleaned.csv", "V√™tements Homme (Nettoy√©es)"),
                (f"{base_path}/chaussures_homme_cleaned.csv", "Chaussures Homme (Nettoy√©es)"),
                (f"{base_path}/vetements_enfants_cleaned.csv", "V√™tements Enfants (Nettoy√©es)"),
                (f"{base_path}/chaussures_enfants_cleaned.csv", "Chaussures Enfants (Nettoy√©es)")
            ]

            
            for filepath, category in possible_files:
                df = load_data_from_csv(filepath)
                if not df.empty:
                    all_sources.append(df)
                    st.info(f'‚úÖ {category}: {len(df)} articles charg√©s')
            
            if all_sources:
                combined_df = pd.concat(all_sources, ignore_index=True)
                # Supprimer les doublons
                combined_df = combined_df.drop_duplicates()
                cleaned_combined = clean_scraped_data(combined_df)
                
                st.success(f'üéâ Dashboard g√©n√©r√© avec {len(cleaned_combined)} articles uniques')
                create_dashboard(cleaned_combined)
            else:
                st.warning('‚ö†Ô∏è Aucune donn√©e trouv√©e. Veuillez d\'abord scraper des donn√©es.')

else:  # Formulaire d'√©valuation
    st.markdown("""
        <div style='background-color: #f8d7da; padding: 1rem; border-radius: 10px; margin: 1rem 0;'>
            <h3 style='color: #721c24; margin-bottom: 1rem;'>üìù Formulaire d'√©valuation</h3>
            <p>Donnez votre avis sur cette application via KoboToolbox.</p>
        </div>
    """, unsafe_allow_html=True)
    
    
# üîÅ Section d'√©valuation externe avec iframe + fallback
st.markdown("---")
st.markdown("### üåê Formulaire KoboToolbox")

try:
    components.html("""
        <div style='text-align: center; margin: 2rem 0;'>
            <h4>√âvaluez cette application sur KoboToolbox</h4>
            <p>Votre feedback d√©taill√© nous aide √† am√©liorer l'application.</p>
            <iframe src='https://ee.kobotoolbox.org/i/fBmPGz9P' width="800" height="600"></iframe>
        </div>
    """, height=650)
except:
    st.warning("‚ö†Ô∏è Le formulaire int√©gr√© n'a pas pu s'afficher. Cliquez ci-dessous pour y acc√©der :")
    st.markdown("[üìù Acc√©der au formulaire KoboToolbox](https://ee.kobotoolbox.org/i/fBmPGz9P)", unsafe_allow_html=True)


# Footer
st.markdown("---")
st.markdown("""
    <div style='text-align: center; padding: 2rem; margin-top: 3rem; border-top: 1px solid #ddd;'>
        <p style='color: #666; margin: 0;'>
            üöÄ Coinafrique Scraper - D√©velopp√© avec Streamlit et BeautifulSoup
        </p>
        <p style='color: #999; font-size: 0.8rem; margin: 0.5rem 0 0 0;'>
            Scraping BeautifulSoup (nettoyage) | Web Scraper (donn√©es brutes) | Dashboard interactif | √âvaluation
        </p>
        <p style='color: #999; font-size: 0.8rem; margin: 0.5rem 0 0 0;'>
            Pour toute question ou suggestion, contactez l'√©quipe de d√©veloppement
        </p>
    </div>
""", unsafe_allow_html=True)
