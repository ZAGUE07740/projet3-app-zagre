import streamlit as st
import pandas as pd
import requests
from bs4 import BeautifulSoup
import base64
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np
import streamlit.components.v1 as components
import plotly.express as px
import plotly.graph_objects as go
from datetime import datetime
import matplotlib as mp
import re
import os
import time

# Palette de couleurs
COLOR_PRIMARY = "#1976D2"
COLOR_BG = "#F4F7FA"
COLOR_ACCENT = "#FFB300"
COLOR_SUCCESS = "#43A047"
COLOR_ERROR = "#E53935"
COLOR_TEXT = "#222C36"
COLOR_TEXT_SECONDARY = "#5A7184"

# Configuration de la page
st.set_page_config(
    page_title="Analyse & Scraping CoinAfrique",
    page_icon="ğŸ“ˆ",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Titre principal avec style
st.markdown(f"""
    <h1 style='text-align: center; color: {COLOR_PRIMARY}; font-size: 3rem; margin-bottom: 0;'>
        ğŸ“ˆ Analyse et Scraping CoinAfrique
    </h1>
    <p style='text-align: center; color: {COLOR_TEXT_SECONDARY}; font-size: 1.2rem; margin-bottom: 2rem;'>
        Collecte, nettoyage et visualisation de donnÃ©es des annonces CoinAfrique SÃ©nÃ©gal
    </p>
""", unsafe_allow_html=True)

# Description de l'app
st.markdown(f"""
    <div style='background-color: {COLOR_BG}; padding: 1rem; border-radius: 10px; margin: 1rem 0;'>
        <p>
            FonctionnalitÃ©sâ€¯:
            <ul>
                <li>ğŸ§¹ Scraping nettoyÃ© (BeautifulSoup)</li>
                <li>ğŸ•¸ï¸ Scraping brut (Web Scraper)</li>
                <li>ğŸ’¾ TÃ©lÃ©chargement de CSV</li>
                <li>ğŸ“ˆ Dashboard interactif</li>
                <li>ğŸ—¨ï¸ Formulaire dâ€™Ã©valuation</li>
            </ul>
            <br>Sourcesâ€¯: <a href="https://sn.coinafrique.com/">Coinafrique SÃ©nÃ©gal</a>
        </p>
    </div>
""", unsafe_allow_html=True)

# Fonction de scraping avec BeautifulSoup (avec nettoyage)
def scrape_with_beautifulsoup(url_base, category_name, pages, clean_data=True):
    """Scraper avec BeautifulSoup et nettoyage optionnel"""
    data = []
    
    # CrÃ©er une barre de progression
    progress_bar = st.progress(0)
    status_text = st.empty()
    
    for page in range(1, pages + 1):
        status_text.text(f'Scraping page {page}/{pages} - {category_name}...')
        progress_bar.progress(page / pages)
        
        url = f"{url_base}?page={page}"
        
        try:
            # Ajouter un dÃ©lai pour Ã©viter de surcharger le serveur
            time.sleep(1)
            
            headers = {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
            }
            response = requests.get(url, headers=headers, timeout=10)
            response.raise_for_status()
            
            soup = BeautifulSoup(response.text, 'html.parser')
            annonces = soup.find_all('div', class_='ad__card')
            
            for annonce in annonces:
                try:
                    # Extraire le type (vÃªtement ou chaussure)
                    type_element = annonce.find('p', class_='ad__card-description')
                    type_item = type_element.get_text(strip=True) if type_element else "Non spÃ©cifiÃ©"
                    
                    # Extraire le prix
                    prix_element = annonce.find('p', class_='ad__card-price')
                    prix = prix_element.get_text(strip=True) if prix_element else "Prix non spÃ©cifiÃ©"
                    
                    # Extraire l'adresse
                    location_element = annonce.find('p', class_='ad__card-location')
                    if location_element:
                        span_element = location_element.find('span')
                        adresse = span_element.get_text(strip=True) if span_element else "Adresse non spÃ©cifiÃ©e"
                    else:
                        adresse = "Adresse non spÃ©cifiÃ©e"
                    
                    # Extraire le lien de l'image
                    img_element = annonce.find('img', class_='ad__card-img')
                    image_lien = img_element['src'] if img_element and 'src' in img_element.attrs else "Image non disponible"
                    
                    data.append({
                        "categorie": category_name,
                        "type": type_item,
                        "prix": prix,
                        "adresse": adresse,
                        "image_lien": image_lien
                    })
                    
                except Exception as e:
                    continue
                    
        except requests.exceptions.RequestException as e:
            st.error(f"Erreur lors du scraping de la page {page}: {str(e)}")
            continue
        except Exception as e:
            st.error(f"Erreur inattendue page {page}: {str(e)}")
            continue
    
    progress_bar.empty()
    status_text.empty()
    
    df = pd.DataFrame(data)
    
    # Nettoyer les donnÃ©es si demandÃ©
    if clean_data and not df.empty:
        df = clean_scraped_data(df)
    
    return df

# Fonction de nettoyage des donnÃ©es
def clean_scraped_data(df):
    """Nettoyer les donnÃ©es scrapÃ©es avec vÃ©rification des colonnes"""
    if df.empty:
        return df

    df_clean = df.copy()

    if 'prix' in df_clean.columns:
        df_clean['prix_brut'] = df_clean['prix']
        df_clean['prix_numerique'] = df_clean['prix'].str.replace(r'[^\d]', '', regex=True)
        df_clean['prix_numerique'] = pd.to_numeric(df_clean['prix_numerique'], errors='coerce')
        df_clean['a_prix'] = df_clean['prix_numerique'].notna()
    else:
        df_clean['prix_brut'] = "Inconnu"
        df_clean['prix_numerique'] = np.nan
        df_clean['a_prix'] = False

    if 'adresse' in df_clean.columns:
        df_clean['adresse'] = df_clean['adresse'].str.strip().str.title()
    else:
        df_clean['adresse'] = "Adresse inconnue"

    if 'type' in df_clean.columns:
        df_clean['type'] = df_clean['type'].str.strip().str.title()
    else:
        df_clean['type'] = "Type inconnu"

    if 'image_lien' in df_clean.columns:
        df_clean['a_image'] = df_clean['image_lien'] != "Image non disponible"
    else:
        df_clean['a_image'] = False

    df_clean = df_clean.drop_duplicates(subset=['type', 'prix_brut', 'adresse'])

    return df_clean


# Fonction pour convertir le DataFrame en CSV
def convert_df_to_csv(df):
    """Convertir DataFrame en CSV"""
    return df.to_csv(index=False).encode('utf-8')

# Fonction pour sauvegarder les donnÃ©es
def save_data_to_csv(df, filename):
    """Sauvegarder les donnÃ©es dans un fichier CSV"""
    if not df.empty:
        df.to_csv(filename, index=False)
        return True
    return False

# Fonction pour charger les donnÃ©es depuis un fichier CSV
def load_data_from_csv(filepath):
    """Charger les donnÃ©es depuis un fichier CSV avec gestion des erreurs"""
    try:
        if os.path.exists(filepath):
            return pd.read_csv(filepath, encoding='utf-8')
        else:
            st.warning(f"ğŸ“‚ Fichier introuvable : {filepath}")
            return pd.DataFrame()
    except pd.errors.ParserError as e:
        st.error(f"âŒ Erreur de format dans {filepath} : {str(e)}")
        return pd.DataFrame()
    except Exception as e:
        st.error(f"âŒ Erreur inconnue lors du chargement de {filepath} : {str(e)}")
        return pd.DataFrame()


# Fonction pour crÃ©er le dashboard
def create_dashboard(df):
    """CrÃ©er un dashboard interactif"""
    if df.empty:
        st.warning('âš ï¸ Aucune donnÃ©e disponible pour le dashboard.')
        return
    
    st.markdown("""
        <h2 style='text-align: center; color: #2E86AB; margin: 2rem 0;'>
            ğŸ“Š DASHBOARD ANALYTIQUE
        </h2>
    """, unsafe_allow_html=True)
    
    # MÃ©triques principales
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric("ğŸ“ Total articles", len(df))
    
    with col2:
        if 'prix_numerique' in df.columns:
            prix_valides = df['prix_numerique'].dropna()
            if not prix_valides.empty:
                prix_moyen = prix_valides.mean()
                st.metric("ğŸ’° Prix moyen", f"{prix_moyen:,.0f} FCFA")
            else:
                st.metric("ğŸ’° Prix moyen", "N/A")
        else:
            st.metric("ğŸ’° Prix moyen", "N/A")
    
    with col3:
        nb_categories = df['categorie'].nunique()
        st.metric("ğŸ·ï¸ CatÃ©gories", nb_categories)
    
    with col4:
        nb_villes = df['adresse'].nunique()
        st.metric("ğŸ™ï¸ Villes", nb_villes)
    
    # Graphiques
    col1, col2 = st.columns(2)
    
    with col1:
        # Distribution par catÃ©gorie
        fig_cat = px.pie(
            df, 
            names='categorie', 
            title='Distribution par CatÃ©gorie',
            color_discrete_sequence=px.colors.qualitative.Set3
        )
        fig_cat.update_layout(height=400)
        st.plotly_chart(fig_cat, use_container_width=True)
    
    with col2:
        # Top 10 des villes
        top_villes = df['adresse'].value_counts().head(10)
        fig_villes = px.bar(
            x=top_villes.values,
            y=top_villes.index,
            orientation='h',
            title='Top 10 des Villes',
            labels={'x': 'Nombre d\'articles', 'y': 'Ville'}
        )
        fig_villes.update_layout(height=400)
        st.plotly_chart(fig_villes, use_container_width=True)
    
    # Analyse des prix si disponible
    if 'prix_numerique' in df.columns:
        prix_valides = df.dropna(subset=['prix_numerique'])
        if not prix_valides.empty:
            col1, col2 = st.columns(2)
            
            with col1:
                # Distribution des prix par catÃ©gorie
                fig_prix = px.box(
                    prix_valides, 
                    x='categorie', 
                    y='prix_numerique',
                    title='Distribution des Prix par CatÃ©gorie'
                )
                fig_prix.update_layout(height=400)
                fig_prix.update_xaxes(tickangle=45)
                st.plotly_chart(fig_prix, use_container_width=True)
            
            with col2:
                # Histogramme des prix
                fig_hist = px.histogram(
                    prix_valides, 
                    x='prix_numerique',
                    title='Distribution des Prix',
                    nbins=30
                )
                fig_hist.update_layout(height=400)
                st.plotly_chart(fig_hist, use_container_width=True)

# Sidebar pour les paramÃ¨tres
st.sidebar.header('ğŸ”§ ParamÃ¨tres de Configuration')
st.sidebar.markdown("---")

# SÃ©lection du nombre de pages
pages = st.sidebar.selectbox(
    'ğŸ“„ Nombre de pages Ã  scraper',
    options=list(range(1, 21)),
    index=2,  # Par dÃ©faut 3 pages
    help="SÃ©lectionnez le nombre de pages Ã  scraper pour chaque catÃ©gorie"
)

# Options principales
choices = st.sidebar.selectbox(
    'ğŸ¯ Choisissez une option',
    options=[
        'Scraper avec BeautifulSoup (nettoyage)',
        'Scraper avec Web Scraper (donnÃ©es brutes)',
        'TÃ©lÃ©charger donnÃ©es prÃ©-scrapÃ©es',
        'Dashboard des donnÃ©es nettoyÃ©es',
        'Formulaire d\'Ã©valuation'
    ],
    help="SÃ©lectionnez l'action que vous souhaitez effectuer"
)

st.sidebar.markdown("---")

# Configuration des chemins pour les fichiers prÃ©-scrapÃ©s
if choices == 'TÃ©lÃ©charger donnÃ©es prÃ©-scrapÃ©es':
    st.sidebar.subheader('ğŸ“ Chemins des fichiers CSV')
    
    vetements_homme_path = st.sidebar.text_input(
        'VÃªtements Homme CSV',
        value='data/vetements_homme.csv',
        help='Chemin vers le fichier CSV des vÃªtements homme'
    )
    
    chaussures_homme_path = st.sidebar.text_input(
        'Chaussures Homme CSV',
        value='data/chaussures_homme.csv',
        help='Chemin vers le fichier CSV des chaussures homme'
    )
    
    vetements_enfants_path = st.sidebar.text_input(
        'VÃªtements Enfants CSV',
        value='data/vetements_enfants.csv',
        help='Chemin vers le fichier CSV des vÃªtements enfants'
    )
    
    chaussures_enfants_path = st.sidebar.text_input(
        'Chaussures Enfants CSV',
        value='data/chaussures_enfants.csv',
        help='Chemin vers le fichier CSV des chaussures enfants'
    )

st.sidebar.markdown("---")
st.sidebar.markdown("""
    <div style='text-align: center; color: #666; font-size: 0.8rem;'>
        <p>Emmanuel ZAGRE</p>
        <p>Â© 2025 Analyse & Scraping CoinAfrique</p>
    </div>
""", unsafe_allow_html=True)

# Interface principale
if choices == 'Scraper avec BeautifulSoup (nettoyage)':
    st.markdown("""
        <div style='background-color: #e8f4f8; padding: 1rem; border-radius: 10px; margin: 1rem 0;'>
            <h3 style='color: #2E86AB; margin-bottom: 1rem;'>ğŸ”„ Scraping avec BeautifulSoup et nettoyage</h3>
            <p>Cliquez sur les boutons ci-dessous pour scraper et nettoyer les donnÃ©es en temps rÃ©el depuis Coinafrique.</p>
        </div>
    """, unsafe_allow_html=True)
    
    # URLs de base pour chaque catÃ©gorie
    urls = {
        'VÃªtements Homme': 'https://sn.coinafrique.com/categorie/vetements-homme',
        'Chaussures Homme': 'https://sn.coinafrique.com/categorie/chaussures-homme',
        'VÃªtements Enfants': 'https://sn.coinafrique.com/categorie/vetements-enfants',
        'Chaussures Enfants': 'https://sn.coinafrique.com/categorie/chaussures-enfants'
    }
    
    # CrÃ©er les colonnes pour les boutons
    col1, col2 = st.columns(2)
    
    with col1:
        # VÃªtements Homme
        st.markdown("### ğŸ‘” VÃªtements Homme")
        if st.button('ğŸš€ Scraper VÃªtements Homme', key='scrape_vh', use_container_width=True):
            with st.spinner('Scraping en cours...'):
                df = scrape_with_beautifulsoup(urls['VÃªtements Homme'], 'VÃªtements Homme', pages, clean_data=True)
                if not df.empty:
                    st.success(f'âœ… {len(df)} articles rÃ©cupÃ©rÃ©s et nettoyÃ©s!')
                    st.info(f'ğŸ“Š Dimensions: {df.shape[0]} lignes et {df.shape[1]} colonnes')
                    st.dataframe(df.head(), use_container_width=True)
                    
                    # Sauvegarder automatiquement
                    if save_data_to_csv(df, 'vetements_homme_cleaned.csv'):
                        st.success('ğŸ’¾ DonnÃ©es sauvegardÃ©es dans vetements_homme_cleaned.csv')
                    
                    # Bouton de tÃ©lÃ©chargement
                    csv = convert_df_to_csv(df)
                    st.download_button(
                        label="ğŸ“¥ TÃ©lÃ©charger CSV",
                        data=csv,
                        file_name=f'vetements_homme_cleaned_{datetime.now().strftime("%Y%m%d_%H%M%S")}.csv',
                        mime='text/csv',
                        key='download_vh'
                    )
                else:
                    st.warning('âš ï¸ Aucune donnÃ©e rÃ©cupÃ©rÃ©e.')
        
        # VÃªtements Enfants
        st.markdown("### ğŸ‘¶ VÃªtements Enfants")
        if st.button('ğŸš€ Scraper VÃªtements Enfants', key='scrape_ve', use_container_width=True):
            with st.spinner('Scraping en cours...'):
                df = scrape_with_beautifulsoup(urls['VÃªtements Enfants'], 'VÃªtements Enfants', pages, clean_data=True)
                if not df.empty:
                    st.success(f'âœ… {len(df)} articles rÃ©cupÃ©rÃ©s et nettoyÃ©s!')
                    st.info(f'ğŸ“Š Dimensions: {df.shape[0]} lignes et {df.shape[1]} colonnes')
                    st.dataframe(df.head(), use_container_width=True)
                    
                    # Sauvegarder automatiquement
                    if save_data_to_csv(df, 'vetements_enfants_cleaned.csv'):
                        st.success('ğŸ’¾ DonnÃ©es sauvegardÃ©es dans vetements_enfants_cleaned.csv')
                    
                    # Bouton de tÃ©lÃ©chargement
                    csv = convert_df_to_csv(df)
                    st.download_button(
                        label="ğŸ“¥ TÃ©lÃ©charger CSV",
                        data=csv,
                        file_name=f'vetements_enfants_cleaned_{datetime.now().strftime("%Y%m%d_%H%M%S")}.csv',
                        mime='text/csv',
                        key='download_ve'
                    )
                else:
                    st.warning('âš ï¸ Aucune donnÃ©e rÃ©cupÃ©rÃ©e.')
    
    with col2:
        # Chaussures Homme
        st.markdown("### ğŸ‘ Chaussures Homme")
        if st.button('ğŸš€ Scraper Chaussures Homme', key='scrape_ch', use_container_width=True):
            with st.spinner('Scraping en cours...'):
                df = scrape_with_beautifulsoup(urls['Chaussures Homme'], 'Chaussures Homme', pages, clean_data=True)
                if not df.empty:
                    st.success(f'âœ… {len(df)} articles rÃ©cupÃ©rÃ©s et nettoyÃ©s!')
                    st.info(f'ğŸ“Š Dimensions: {df.shape[0]} lignes et {df.shape[1]} colonnes')
                    st.dataframe(df.head(), use_container_width=True)
                    
                    # Sauvegarder automatiquement
                    if save_data_to_csv(df, 'chaussures_homme_cleaned.csv'):
                        st.success('ğŸ’¾ DonnÃ©es sauvegardÃ©es dans chaussures_homme_cleaned.csv')
                    
                    # Bouton de tÃ©lÃ©chargement
                    csv = convert_df_to_csv(df)
                    st.download_button(
                        label="ğŸ“¥ TÃ©lÃ©charger CSV",
                        data=csv,
                        file_name=f'chaussures_homme_cleaned_{datetime.now().strftime("%Y%m%d_%H%M%S")}.csv',
                        mime='text/csv',
                        key='download_ch'
                    )
                else:
                    st.warning('âš ï¸ Aucune donnÃ©e rÃ©cupÃ©rÃ©e.')
        
        # Chaussures Enfants
        st.markdown("### ğŸ‘Ÿ Chaussures Enfants")
        if st.button('ğŸš€ Scraper Chaussures Enfants', key='scrape_ce', use_container_width=True):
            with st.spinner('Scraping en cours...'):
                df = scrape_with_beautifulsoup(urls['Chaussures Enfants'], 'Chaussures Enfants', pages, clean_data=True)
                if not df.empty:
                    st.success(f'âœ… {len(df)} articles rÃ©cupÃ©rÃ©s et nettoyÃ©s!')
                    st.info(f'ğŸ“Š Dimensions: {df.shape[0]} lignes et {df.shape[1]} colonnes')
                    st.dataframe(df.head(), use_container_width=True)
                    
                    # Sauvegarder automatiquement
                    if save_data_to_csv(df, 'chaussures_enfants_cleaned.csv'):
                        st.success('ğŸ’¾ DonnÃ©es sauvegardÃ©es dans chaussures_enfants_cleaned.csv')
                    
                    # Bouton de tÃ©lÃ©chargement
                    csv = convert_df_to_csv(df)
                    st.download_button(
                        label="ğŸ“¥ TÃ©lÃ©charger CSV",
                        data=csv,
                        file_name=f'chaussures_enfants_cleaned_{datetime.now().strftime("%Y%m%d_%H%M%S")}.csv',
                        mime='text/csv',
                        key='download_ce'
                    )
                else:
                    st.warning('âš ï¸ Aucune donnÃ©e rÃ©cupÃ©rÃ©e.')

elif choices == 'Scraper avec Web Scraper (donnÃ©es brutes)':
    st.markdown("""
        <div style='background-color: #fff3cd; padding: 1rem; border-radius: 10px; margin: 1rem 0;'>
            <h3 style='color: #856404; margin-bottom: 1rem;'>ğŸ”„ Scraping avec Web Scraper (donnÃ©es brutes)</h3>
            <p>Cliquez sur les boutons ci-dessous pour scraper les donnÃ©es brutes (non nettoyÃ©es) depuis Coinafrique.</p>
        </div>
    """, unsafe_allow_html=True)
    
    # URLs de base pour chaque catÃ©gorie
    urls = {
        'VÃªtements Homme': 'https://sn.coinafrique.com/categorie/vetements-homme',
        'Chaussures Homme': 'https://sn.coinafrique.com/categorie/chaussures-homme',
        'VÃªtements Enfants': 'https://sn.coinafrique.com/categorie/vetements-enfants',
        'Chaussures Enfants': 'https://sn.coinafrique.com/categorie/chaussures-enfants'
    }
    
    # CrÃ©er les colonnes pour les boutons
    col1, col2 = st.columns(2)
    
    with col1:
        # VÃªtements Homme
        st.markdown("### ğŸ‘” VÃªtements Homme")
        if st.button('ğŸš€ Scraper VÃªtements Homme (Brut)', key='scrape_vh_raw', use_container_width=True):
            with st.spinner('Scraping en cours...'):
                df = scrape_with_beautifulsoup(urls['VÃªtements Homme'], 'VÃªtements Homme', pages, clean_data=False)
                if not df.empty:
                    st.success(f'âœ… {len(df)} articles rÃ©cupÃ©rÃ©s (donnÃ©es brutes)!')
                    st.info(f'ğŸ“Š Dimensions: {df.shape[0]} lignes et {df.shape[1]} colonnes')
                    st.dataframe(df.head(), use_container_width=True)
                    
                    # Sauvegarder automatiquement
                    if save_data_to_csv(df, 'vetements_homme_raw.csv'):
                        st.success('ğŸ’¾ DonnÃ©es sauvegardÃ©es dans vetements_homme_raw.csv')
                    
                    # Bouton de tÃ©lÃ©chargement
                    csv = convert_df_to_csv(df)
                    st.download_button(
                        label="ğŸ“¥ TÃ©lÃ©charger CSV",
                        data=csv,
                        file_name=f'vetements_homme_raw_{datetime.now().strftime("%Y%m%d_%H%M%S")}.csv',
                        mime='text/csv',
                        key='download_vh_raw'
                    )
                else:
                    st.warning('âš ï¸ Aucune donnÃ©e rÃ©cupÃ©rÃ©e.')
        
        # VÃªtements Enfants
        st.markdown("### ğŸ‘¶ VÃªtements Enfants")
        if st.button('ğŸš€ Scraper VÃªtements Enfants (Brut)', key='scrape_ve_raw', use_container_width=True):
            with st.spinner('Scraping en cours...'):
                df = scrape_with_beautifulsoup(urls['VÃªtements Enfants'], 'VÃªtements Enfants', pages, clean_data=False)
                if not df.empty:
                    st.success(f'âœ… {len(df)} articles rÃ©cupÃ©rÃ©s (donnÃ©es brutes)!')
                    st.info(f'ğŸ“Š Dimensions: {df.shape[0]} lignes et {df.shape[1]} colonnes')
                    st.dataframe(df.head(), use_container_width=True)
                    
                    # Sauvegarder automatiquement
                    if save_data_to_csv(df, 'vetements_enfants_raw.csv'):
                        st.success('ğŸ’¾ DonnÃ©es sauvegardÃ©es dans vetements_enfants_raw.csv')
                    
                    # Bouton de tÃ©lÃ©chargement
                    csv = convert_df_to_csv(df)
                    st.download_button(
                        label="ğŸ“¥ TÃ©lÃ©charger CSV",
                        data=csv,
                        file_name=f'vetements_enfants_raw_{datetime.now().strftime("%Y%m%d_%H%M%S")}.csv',
                        mime='text/csv',
                        key='download_ve_raw'
                    )
                else:
                    st.warning('âš ï¸ Aucune donnÃ©e rÃ©cupÃ©rÃ©e.')
    
    with col2:
        # Chaussures Homme
        st.markdown("### ğŸ‘ Chaussures Homme")
        if st.button('ğŸš€ Scraper Chaussures Homme (Brut)', key='scrape_ch_raw', use_container_width=True):
            with st.spinner('Scraping en cours...'):
                df = scrape_with_beautifulsoup(urls['Chaussures Homme'], 'Chaussures Homme', pages, clean_data=False)
                if not df.empty:
                    st.success(f'âœ… {len(df)} articles rÃ©cupÃ©rÃ©s (donnÃ©es brutes)!')
                    st.info(f'ğŸ“Š Dimensions: {df.shape[0]} lignes et {df.shape[1]} colonnes')
                    st.dataframe(df.head(), use_container_width=True)
                    
                    # Sauvegarder automatiquement
                    if save_data_to_csv(df, 'chaussures_homme_raw.csv'):
                        st.success('ğŸ’¾ DonnÃ©es sauvegardÃ©es dans chaussures_homme_raw.csv')
                    
                    # Bouton de tÃ©lÃ©chargement
                    csv = convert_df_to_csv(df)
                    st.download_button(
                        label="ğŸ“¥ TÃ©lÃ©charger CSV",
                        data=csv,
                        file_name=f'chaussures_homme_raw_{datetime.now().strftime("%Y%m%d_%H%M%S")}.csv',
                        mime='text/csv',
                        key='download_ch_raw'
                    )
                else:
                    st.warning('âš ï¸ Aucune donnÃ©e rÃ©cupÃ©rÃ©e.')
        
        # Chaussures Enfants
        st.markdown("### ğŸ‘Ÿ Chaussures Enfants")
        if st.button('ğŸš€ Scraper Chaussures Enfants (Brut)', key='scrape_ce_raw', use_container_width=True):
            with st.spinner('Scraping en cours...'):
                df = scrape_with_beautifulsoup(urls['Chaussures Enfants'], 'Chaussures Enfants', pages, clean_data=False)
                if not df.empty:
                    st.success(f'âœ… {len(df)} articles rÃ©cupÃ©rÃ©s (donnÃ©es brutes)!')
                    st.info(f'ğŸ“Š Dimensions: {df.shape[0]} lignes et {df.shape[1]} colonnes')
                    st.dataframe(df.head(), use_container_width=True)
                    
                    # Sauvegarder automatiquement
                    if save_data_to_csv(df, 'chaussures_enfants_raw.csv'):
                        st.success('ğŸ’¾ DonnÃ©es sauvegardÃ©es dans chaussures_enfants_raw.csv')
                    
                    # Bouton de tÃ©lÃ©chargement
                    csv = convert_df_to_csv(df)
                    st.download_button(
                        label="ğŸ“¥ TÃ©lÃ©charger CSV",
                        data=csv,
                        file_name=f'chaussures_enfants_raw_{datetime.now().strftime("%Y%m%d_%H%M%S")}.csv',
                        mime='text/csv',
                        key='download_ce_raw'
                    )
                else:
                    st.warning('âš ï¸ Aucune donnÃ©e rÃ©cupÃ©rÃ©e.')

elif choices == 'TÃ©lÃ©charger donnÃ©es prÃ©-scrapÃ©es':
    st.markdown("""
        <div style='background-color: #d1ecf1; padding: 1rem; border-radius: 10px; margin: 1rem 0;'>
            <h3 style='color: #0c5460; margin-bottom: 1rem;'>ğŸ“¥ TÃ©lÃ©charger donnÃ©es prÃ©-scrapÃ©es</h3>
            <p>Chargez et tÃ©lÃ©chargez les donnÃ©es qui ont Ã©tÃ© prÃ©-scrapÃ©es et sauvegardÃ©es dans des fichiers CSV.</p>
        </div>
    """, unsafe_allow_html=True)
    
    # CrÃ©er les colonnes pour les boutons
    col1, col2 = st.columns(2)
    
    with col1:
        # VÃªtements Homme
        st.markdown("### ğŸ‘” VÃªtements Homme")
        if st.button('ğŸ“‚ Charger VÃªtements Homme', key='load_vh', use_container_width=True):
            df = load_data_from_csv(vetements_homme_path)
            if not df.empty:
                st.success(f'âœ… {len(df)} articles chargÃ©s depuis {vetements_homme_path}!')
                st.info(f'ğŸ“Š Dimensions: {df.shape[0]} lignes et {df.shape[1]} colonnes')
                st.dataframe(df.head(10), use_container_width=True)
                
                # Bouton de tÃ©lÃ©chargement
                csv = convert_df_to_csv(df)
                st.download_button(
                    label="ğŸ“¥ TÃ©lÃ©charger CSV",
                    data=csv,
                    file_name=f'vetements_homme_prescraped_{datetime.now().strftime("%Y%m%d_%H%M%S")}.csv',
                    mime='text/csv',
                    key='download_vh_pre'
                )
            else:
                st.warning('âš ï¸ Aucune donnÃ©e trouvÃ©e ou fichier inexistant.')
        
        # VÃªtements Enfants
        st.markdown("### ğŸ‘¶ VÃªtements Enfants")
        if st.button('ğŸ“‚ Charger VÃªtements Enfants', key='load_ve', use_container_width=True):
            df = load_data_from_csv(vetements_enfants_path)
            if not df.empty:
                st.success(f'âœ… {len(df)} articles chargÃ©s depuis {vetements_enfants_path}!')
                st.info(f'ğŸ“Š Dimensions: {df.shape[0]} lignes et {df.shape[1]} colonnes')
                st.dataframe(df.head(10), use_container_width=True)
                
                # Bouton de tÃ©lÃ©chargement
                csv = convert_df_to_csv(df)
                st.download_button(
                    label="ğŸ“¥ TÃ©lÃ©charger CSV",
                    data=csv,
                    file_name=f'vetements_enfants_prescraped_{datetime.now().strftime("%Y%m%d_%H%M%S")}.csv',
                    mime='text/csv',
                    key='download_ve_pre'
                )
            else:
                st.warning('âš ï¸ Aucune donnÃ©e trouvÃ©e ou fichier inexistant.')
    
    with col2:
        # Chaussures Homme
        st.markdown("### ğŸ‘ Chaussures Homme")
        if st.button('ğŸ“‚ Charger Chaussures Homme', key='load_ch', use_container_width=True):
            df = load_data_from_csv(chaussures_homme_path)
            if not df.empty:
                st.success(f'âœ… {len(df)} articles chargÃ©s depuis {chaussures_homme_path}!')
                st.info(f'ğŸ“Š Dimensions: {df.shape[0]} lignes et {df.shape[1]} colonnes')
                st.dataframe(df.head(10), use_container_width=True)
                
                # Bouton de tÃ©lÃ©chargement
                csv = convert_df_to_csv(df)
                st.download_button(
                    label="ğŸ“¥ TÃ©lÃ©charger CSV",
                    data=csv,
                    file_name=f'chaussures_homme_prescraped_{datetime.now().strftime("%Y%m%d_%H%M%S")}.csv',
                    mime='text/csv',
                    key='download_ch_pre'
                )
            else:
                st.warning('âš ï¸ Aucune donnÃ©e trouvÃ©e ou fichier inexistant.')
        
        # Chaussures Enfants
        st.markdown("### ğŸ‘Ÿ Chaussures Enfants")
        if st.button('ğŸ“‚ Charger Chaussures Enfants', key='load_ce', use_container_width=True):
            df = load_data_from_csv(chaussures_enfants_path)
            if not df.empty:
                st.success(f'âœ… {len(df)} articles chargÃ©s depuis {chaussures_enfants_path}!')
                st.info(f'ğŸ“Š Dimensions: {df.shape[0]} lignes et {df.shape[1]} colonnes')
                st.dataframe(df.head(10), use_container_width=True)
                
                # Bouton de tÃ©lÃ©chargement
                csv = convert_df_to_csv(df)
                st.download_button(
                    label="ğŸ“¥ TÃ©lÃ©charger CSV",
                    data=csv,
                    file_name=f'chaussures_enfants_prescraped_{datetime.now().strftime("%Y%m%d_%H%M%S")}.csv',
                    mime='text/csv',
                    key='download_ce_pre'
                )
            else:
                st.warning('âš ï¸ Aucune donnÃ©e trouvÃ©e ou fichier inexistant.')
    
    # Section pour charger tous les fichiers Ã  la fois
    st.markdown("---")
    st.markdown("### ğŸ“Š Charger toutes les donnÃ©es")
    
    if st.button('ğŸ“‚ Charger toutes les catÃ©gories', key='load_all', use_container_width=True):
        all_data = []
        paths = [
            (vetements_homme_path, 'VÃªtements Homme'),
            (chaussures_homme_path, 'Chaussures Homme'),
            (vetements_enfants_path, 'VÃªtements Enfants'),
            (chaussures_enfants_path, 'Chaussures Enfants')
        ]
        
        for path, category in paths:
            df = load_data_from_csv(path)
            if not df.empty:
                all_data.append(df)
                st.success(f'âœ… {category}: {len(df)} articles chargÃ©s')
            else:
                st.warning(f'âš ï¸ {category}: Aucune donnÃ©e trouvÃ©e')
        
        if all_data:
            combined_df = pd.concat(all_data, ignore_index=True)
            st.success(f'ğŸ‰ Total combinÃ©: {len(combined_df)} articles de {len(all_data)} catÃ©gories')
            st.dataframe(combined_df.head(20), use_container_width=True)
            
            # Bouton de tÃ©lÃ©chargement pour toutes les donnÃ©es
            csv_all = convert_df_to_csv(combined_df)
            st.download_button(
                label="ğŸ“¥ TÃ©lÃ©charger toutes les donnÃ©es (CSV)",
                data=csv_all,
                file_name=f'coinafrique_all_data_{datetime.now().strftime("%Y%m%d_%H%M%S")}.csv',
                mime='text/csv',
                key='download_all_pre'
            )

elif choices == 'Dashboard des donnÃ©es nettoyÃ©es':
    st.markdown("""
        <div style='background-color: #d4edda; padding: 1rem; border-radius: 10px; margin: 1rem 0;'>
            <h3 style='color: #155724; margin-bottom: 1rem;'>ğŸ“Š Dashboard des donnÃ©es nettoyÃ©es</h3>
            <p>Visualisez les donnÃ©es nettoyÃ©es sous forme de graphiques interactifs.</p>
        </div>
    """, unsafe_allow_html=True)
    
    # Option pour choisir la source des donnÃ©es
    data_source = st.selectbox(
        'ğŸ“‚ Choisir la source des donnÃ©es',
        options=[
            'Charger depuis fichiers CSV',
            'Utiliser donnÃ©es d\'exemple',
            'Combiner toutes les sources'
        ],
        help="SÃ©lectionnez la source des donnÃ©es pour le dashboard"
    )
    
    if data_source == 'Charger depuis fichiers CSV':
        st.markdown("### ğŸ“ SÃ©lectionner les fichiers Ã  analyser")
        
        # Checkboxes pour sÃ©lectionner les fichiers
        use_vh = st.checkbox('VÃªtements Homme', value=True)
        use_ch = st.checkbox('Chaussures Homme', value=True)
        use_ve = st.checkbox('VÃªtements Enfants', value=True)
        use_ce = st.checkbox('Chaussures Enfants', value=True)
        
        if st.button('ğŸš€ GÃ©nÃ©rer Dashboard', key='generate_dashboard'):
            dashboard_data = []
            
            if use_vh:
                df_vh = load_data_from_csv('data/vetements_homme.csv')
                if not df_vh.empty:
                    dashboard_data.append(df_vh)
            
            if use_ch:
                df_ch = load_data_from_csv('data/chaussures_homme.csv')
                if not df_ch.empty:
                    dashboard_data.append(df_ch)
            
            if use_ve:
                df_ve = load_data_from_csv('data/vetements_enfants.csv')
                if not df_ve.empty:
                    dashboard_data.append(df_ve)
            
            if use_ce:
                df_ce = load_data_from_csv('data/chaussures_enfants.csv')
                if not df_ce.empty:
                    dashboard_data.append(df_ce)
            
            if dashboard_data:
                combined_df = pd.concat(dashboard_data, ignore_index=True)
                # Nettoyer les donnÃ©es avant de crÃ©er le dashboard
                cleaned_df = clean_scraped_data(combined_df)
                create_dashboard(cleaned_df)
            else:
                st.warning('âš ï¸ Aucune donnÃ©e trouvÃ©e dans les fichiers sÃ©lectionnÃ©s.')
    
    elif data_source == 'Utiliser donnÃ©es d\'exemple':
        # CrÃ©er des donnÃ©es d'exemple rÃ©alistes
        sample_data = pd.DataFrame({
            'categorie': ['VÃªtements Homme', 'Chaussures Homme', 'VÃªtements Enfants', 'Chaussures Enfants'] * 50,
            'type': ['Chemise', 'Sneakers', 'T-shirt', 'Sandales'] * 50,
            'prix': ['15000 FCFA', '25000 FCFA', '8000 FCFA', '12000 FCFA'] * 50,
            'adresse': ['Dakar', 'ThiÃ¨s', 'Kaolack', 'Saint-Louis', 'Ziguinchor'] * 40,
            'image_lien': ['https://example.com/img1.jpg'] * 200
        })
        
        # Ajouter de la variabilitÃ©
        np.random.seed(42)
        prix_variations = np.random.normal(1, 0.3, len(sample_data))
        sample_data['prix'] = sample_data['prix'].str.replace(r'[^\d]', '', regex=True).astype(int)
        sample_data['prix'] = (sample_data['prix'] * prix_variations).astype(int)
        sample_data['prix'] = sample_data['prix'].astype(str) + ' FCFA'
        
        cleaned_sample = clean_scraped_data(sample_data)
        create_dashboard(cleaned_sample)
    
    else:  # Combiner toutes les sources
        st.markdown("### ğŸ“Š Dashboard combinÃ©")
        def create_dashboard(df):
            """CrÃ©er un dashboard interactif adaptÃ© Ã  l'application CoinAfrique"""
            if df.empty:
                st.warning('âš ï¸ Aucune donnÃ©e disponible pour le dashboard.')
                return

            st.markdown("""
                <h2 style='text-align: center; color: #2E86AB; margin: 2rem 0;'>
                    ğŸ“Š DASHBOARD ANALYTIQUE
                </h2>
            """, unsafe_allow_html=True)

            # ğŸ”¢ MÃ©triques principales
            col1, col2, col3, col4 = st.columns(4)

            with col1:
                st.metric("ğŸ“ Total articles", len(df))

            with col2:
                if 'prix_numerique' in df.columns and df['prix_numerique'].notna().any():
                    st.metric("ğŸ’° Prix moyen", f"{df['prix_numerique'].mean():,.0f} FCFA")
                else:
                    st.metric("ğŸ’° Prix moyen", "N/A")

            with col3:
                if 'categorie' in df.columns:
                    st.metric("ğŸ·ï¸ CatÃ©gories", df['categorie'].nunique())
                else:
                    st.metric("ğŸ·ï¸ CatÃ©gories", "N/A")

            with col4:
                if 'adresse' in df.columns:
                    st.metric("ğŸ™ï¸ Villes", df['adresse'].nunique())
                else:
                    st.metric("ğŸ™ï¸ Villes", "N/A")

            # ğŸ“ˆ Graphiques
            col1, col2 = st.columns(2)

            with col1:
                if 'categorie' in df.columns:
                    fig_cat = px.pie(
                        df,
                        names='categorie',
                        title='RÃ©partition par catÃ©gorie',
                        color_discrete_sequence=px.colors.qualitative.Set3
                    )
                    fig_cat.update_layout(height=400)
                    st.plotly_chart(fig_cat, use_container_width=True)

            with col2:
                if 'adresse' in df.columns:
                    top_villes = df['adresse'].value_counts().head(10)
                    fig_villes = px.bar(
                        x=top_villes.values,
                        y=top_villes.index,
                        orientation='h',
                        title='Top 10 des villes',
                        labels={'x': 'Nombre d\'articles', 'y': 'Ville'}
                    )
                    fig_villes.update_layout(height=400)
                    st.plotly_chart(fig_villes, use_container_width=True)

            # ğŸ“Š Analyse des prix
            if 'prix_numerique' in df.columns and df['prix_numerique'].notna().any():
                prix_valides = df.dropna(subset=['prix_numerique'])

                col1, col2 = st.columns(2)

                with col1:
                    if 'categorie' in df.columns:
                        fig_box = px.box(
                            prix_valides,
                            x='categorie',
                            y='prix_numerique',
                            title='Distribution des prix par catÃ©gorie'
                        )
                        fig_box.update_layout(height=400)
                        fig_box.update_xaxes(tickangle=45)
                        st.plotly_chart(fig_box, use_container_width=True)

                with col2:
                    fig_hist = px.histogram(
                        prix_valides,
                        x='prix_numerique',
                        nbins=30,
                        title='Distribution des prix'
                    )
                    fig_hist.update_layout(height=400)
                    st.plotly_chart(fig_hist, use_container_width=True)
            if all_sources:
                combined_df = pd.concat(all_sources, ignore_index=True).drop_duplicates()
                cleaned_df = clean_scraped_data(combined_df)

        if 'categorie' not in cleaned_df.columns:
            st.warning("âš ï¸ La colonne 'categorie' est absente. Le dashboard ne peut pas Ãªtre gÃ©nÃ©rÃ©.")
            st.dataframe(cleaned_df.head())
        else:
            create_dashboard(cleaned_df)  # 
            

            
            # Fichiers possibles
            base_path = "C:/Users/ZAGRE/OneDrive/Desktop/ZAGRE-Emmanuel-DC/data"

            possible_files = [
                (f"{base_path}/vetements_homme.csv", "VÃªtements Homme"),
                (f"{base_path}/chaussures_homme.csv", "Chaussures Homme"),
                (f"{base_path}/vetements_enfants.csv", "VÃªtements Enfants"),
                (f"{base_path}/chaussures_enfants.csv", "Chaussures Enfants"),
                (f"{base_path}/vetements_homme_cleaned.csv", "VÃªtements Homme (NettoyÃ©es)"),
                (f"{base_path}/chaussures_homme_cleaned.csv", "Chaussures Homme (NettoyÃ©es)"),
                (f"{base_path}/vetements_enfants_cleaned.csv", "VÃªtements Enfants (NettoyÃ©es)"),
                (f"{base_path}/chaussures_enfants_cleaned.csv", "Chaussures Enfants (NettoyÃ©es)")
            ]

            
            for filepath, category in possible_files:
                df = load_data_from_csv(filepath)
                if not df.empty:
                    all_sources.append(df)
                    st.info(f'âœ… {category}: {len(df)} articles chargÃ©s')
            
            if all_sources:
                combined_df = pd.concat(all_sources, ignore_index=True)
                # Supprimer les doublons
                combined_df = combined_df.drop_duplicates()
                cleaned_combined = clean_scraped_data(combined_df)
                
                st.success(f'ğŸ‰ Dashboard gÃ©nÃ©rÃ© avec {len(cleaned_combined)} articles uniques')
                create_dashboard(cleaned_combined)
            else:
                st.warning('âš ï¸ Aucune donnÃ©e trouvÃ©e. Veuillez d\'abord scraper des donnÃ©es.')

else:  # Formulaire d'Ã©valuation
    st.markdown("""
        <div style='background-color: #f8d7da; padding: 1rem; border-radius: 10px; margin: 1rem 0;'>
            <h3 style='color: #721c24; margin-bottom: 1rem;'>ğŸ“ Formulaire d'Ã©valuation</h3>
            <p>Donnez votre avis sur cette application via KoboToolbox.</p>
        </div>
    """, unsafe_allow_html=True)
    
    
# ğŸ” Section d'Ã©valuation externe avec iframe + fallback
st.markdown("---")
st.markdown("### ğŸŒ Formulaire KoboToolbox")

try:
    components.html("""
        <div style='text-align: center; margin: 2rem 0;'>
            <h4>Ã‰valuez cette application sur KoboToolbox</h4>
            <p>Votre feedback dÃ©taillÃ© nous aide Ã  amÃ©liorer l'application.</p>
            <iframe src='https://ee.kobotoolbox.org/i/fBmPGz9P' width="800" height="600"></iframe>
        </div>
    """, height=650)
except:
    st.warning("âš ï¸ Le formulaire intÃ©grÃ© n'a pas pu s'afficher. Cliquez ci-dessous pour y accÃ©der :")
    st.markdown("[ğŸ“ AccÃ©der au formulaire KoboToolbox](https://ee.kobotoolbox.org/i/fBmPGz9P)", unsafe_allow_html=True)


# Footer
st.markdown("---")
st.markdown("""
    <div style='text-align: center; padding: 2rem; margin-top: 3rem; border-top: 1px solid #ddd;'>
        <p style='color: #666; margin: 0;'>
            ğŸš€ Coinafrique Scraper - DÃ©veloppÃ© avec Streamlit et BeautifulSoup
        </p>
        <p style='color: #999; font-size: 0.8rem; margin: 0.5rem 0 0 0;'>
            Scraping BeautifulSoup (nettoyage) | Web Scraper (donnÃ©es brutes) | Dashboard interactif | Ã‰valuation
        </p>
        <p style='color: #999; font-size: 0.8rem; margin: 0.5rem 0 0 0;'>
            Pour toute question ou suggestion, contactez l'Ã©quipe de dÃ©veloppement
        </p>
    </div>
""", unsafe_allow_html=True)
