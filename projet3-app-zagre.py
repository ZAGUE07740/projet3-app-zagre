import streamlit as st
import pandas as pd
import requests
from bs4 import BeautifulSoup
import base64
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np
import streamlit.components.v1 as components

from datetime import datetime
import re
import os
import time

# Configuration de la page
st.set_page_config(
    page_title="CoinAfrique Scraping and Visualisation",
    page_icon="ğŸ›ï¸",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Titre principal avec style
st.markdown("""
    <h1 style='text-align: center; color: #FF5733; font-size: 3rem; margin-bottom: 0;'>
        ğŸ›ï¸ CoinAfrique's data Scraping and analysing
    </h1>
    <p style='text-align: center; color: #666; font-size: 1.2rem; margin-bottom: 2rem;'>
        Ceci est un outils de collecte et de traitement de donnÃ©es provenant de coinafrque
    </p>
""", unsafe_allow_html=True)

# Description de l'app
st.markdown("""
    <div style='background-color: #f0f2f7; padding: 1rem; border-radius: 10px; margin: 1rem 0;'>
        <p style='margin: 0;'>
            La fonction principal de ce application est de :
                <li> scraper des donnÃ©es suivant plusieurs pages ;
                <li> tÃ©lÃ©charger des donnÃ©es dÃ©jÃ  scrapÃ©es Ã  travers Web Scraper (non nettoyÃ©es) ;
                <li> voir un dashboard des donnÃ©es ( nettoyÃ©es issues de Web Scraper)
                <li> remplir un formulaire dâ€™Ã©valuation de lâ€™app ;<br>
        <br>Les librairies les methodes et sources de donnÃ©es sont : 
        </p>
        <ul style='margin-top: 0.5rem;'>
            <li><strong>Python libraries:</strong> streamlit, pandas, requests, bs4, plotly</li>
            <li><strong>Source de donnÃ©es:</strong> <a href="https://sn.coinafrique.com/">Coinafrique SÃ©nÃ©gal</a></li>
            <li><strong>MÃ©thodes:</strong> BeautifulSoup (nettoyage) et Web Scraper (donnÃ©es brutes)</li>
        </ul>
    </div>
""", unsafe_allow_html=True)

# Fonction de scraping avec BeautifulSoup (avec nettoyage)
def scrape_with_beautifulsoup(url_base, category_name, pages, clean_data=True):
    """Scraper avec BeautifulSoup et nettoyage optionnel"""
    data = []
    
    # CrÃ©er une barre de progression
    progress_bar = st.progress(0)
    status_text = st.empty()
    
    for page in range(1, pages + 1):
        status_text.text(f'Scraping page {page}/{pages} - {category_name}...')
        progress_bar.progress(page / pages)
        
        url = f"{url_base}?page={page}"
        
        try:
            # Ajouter un dÃ©lai pour Ã©viter de surcharger le serveur
            time.sleep(1)
            
            headers = {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
            }
            response = requests.get(url, headers=headers, timeout=10)
            response.raise_for_status()
            
            soup = BeautifulSoup(response.text, 'html.parser')
            annonces = soup.find_all('div', class_='ad__card')
            
            for annonce in annonces:
                try:
                    # Extraire le type (vÃªtement ou chaussure)
                    type_element = annonce.find('p', class_='ad__card-description')
                    type_item = type_element.get_text(strip=True) if type_element else "Non spÃ©cifiÃ©"
                    
                    # Extraire le prix
                    prix_element = annonce.find('p', class_='ad__card-price')
                    prix = prix_element.get_text(strip=True) if prix_element else "Prix non spÃ©cifiÃ©"
                    
                    # Extraire l'adresse
                    location_element = annonce.find('p', class_='ad__card-location')
                    if location_element:
                        span_element = location_element.find('span')
                        adresse = span_element.get_text(strip=True) if span_element else "Adresse non spÃ©cifiÃ©e"
                    else:
                        adresse = "Adresse non spÃ©cifiÃ©e"
                    
                    # Extraire le lien de l'image
                    img_element = annonce.find('img', class_='ad__card-img')
                    image_lien = img_element['src'] if img_element and 'src' in img_element.attrs else "Image non disponible"
                    
                    data.append({
                        "categorie": category_name,
                        "type": type_item,
                        "prix": prix,
                        "adresse": adresse,
                        "image_lien": image_lien
                    })
                    
                except Exception as e:
                    continue
                    
        except requests.exceptions.RequestException as e:
            st.error(f"Erreur lors du scraping de la page {page}: {str(e)}")
            continue
        except Exception as e:
            st.error(f"Erreur inattendue page {page}: {str(e)}")
            continue
    
    progress_bar.empty()
    status_text.empty()
    
    df = pd.DataFrame(data)
    
    # Nettoyer les donnÃ©es si demandÃ©
    if clean_data and not df.empty:
        df = clean_scraped_data(df)
    
    return df

# Fonction de nettoyage des donnÃ©es
def clean_scraped_data(df):
    """Nettoyer les donnÃ©es scrapÃ©es"""
    if df.empty:
        return df
    
    # CrÃ©er une copie pour Ã©viter les modifications inattendues
    df_clean = df.copy()
    
    # Nettoyer les prix - extraire les chiffres
    df_clean['prix_brut'] = df_clean['prix']
    df_clean['prix_numerique'] = df_clean['prix'].str.replace(r'[^\d]', '', regex=True)
    df_clean['prix_numerique'] = pd.to_numeric(df_clean['prix_numerique'], errors='coerce')
    
    # Nettoyer les adresses
    df_clean['adresse'] = df_clean['adresse'].str.strip()
    df_clean['adresse'] = df_clean['adresse'].str.title()
    
    # Nettoyer les types
    df_clean['type'] = df_clean['type'].str.strip()
    df_clean['type'] = df_clean['type'].str.title()
    
    # Ajouter des colonnes d'analyse
    df_clean['a_prix'] = df_clean['prix_numerique'].notna()
    df_clean['a_image'] = df_clean['image_lien'] != "Image non disponible"
    
    # Supprimer les doublons
    df_clean = df_clean.drop_duplicates(subset=['type', 'prix', 'adresse'])
    
    return df_clean

# Fonction pour convertir le DataFrame en CSV
def convert_df_to_csv(df):
    """Convertir DataFrame en CSV"""
    return df.to_csv(index=False).encode('utf-8')

# Fonction pour sauvegarder les donnÃ©es
def save_data_to_csv(df, filename):
    """Sauvegarder les donnÃ©es dans un fichier CSV"""
    if not df.empty:
        df.to_csv(filename, index=False)
        return True
    return False

# Fonction pour charger les donnÃ©es depuis un fichier CSV
def load_data_from_csv(filepath):
    """Charger les donnÃ©es depuis un fichier CSV"""
    try:
        if os.path.exists(filepath):
            return pd.read_csv(filepath)
        else:
            st.error(f"Le fichier {filepath} n'existe pas.")
            return pd.DataFrame()
    except Exception as e:
        st.error(f"Erreur lors du chargement du fichier: {str(e)}")
        return pd.DataFrame()

# Fonction pour crÃ©er le dashboard
def create_dashboard(df):
    """CrÃ©er un dashboard interactif"""
    if df.empty:
        st.warning('âš ï¸ Aucune donnÃ©e disponible pour le dashboard.')
        return
    
    st.markdown("""
        <h2 style='text-align: center; color: #2E86AB; margin: 2rem 0;'>
            ğŸ“Š DASHBOARD ANALYTIQUE
        </h2>
    """, unsafe_allow_html=True)
    
    # MÃ©triques principales
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric("ğŸ“ Total articles", len(df))
    
    with col2:
        if 'prix_numerique' in df.columns:
            prix_valides = df['prix_numerique'].dropna()
            if not prix_valides.empty:
                prix_moyen = prix_valides.mean()
                st.metric("ğŸ’° Prix moyen", f"{prix_moyen:,.0f} FCFA")
            else:
                st.metric("ğŸ’° Prix moyen", "N/A")
        else:
            st.metric("ğŸ’° Prix moyen", "N/A")
    
    with col3:
        nb_categories = df['categorie'].nunique()
        st.metric("ğŸ·ï¸ CatÃ©gories", nb_categories)
    
    with col4:
        nb_villes = df['adresse'].nunique()
        st.metric("ğŸ™ï¸ Villes", nb_villes)
    
    # Graphiques
    col1, col2 = st.columns(2)
    
    with col1:
        # Distribution par catÃ©gorie
        fig_cat = px.pie(
            df, 
            names='categorie', 
            title='Distribution par CatÃ©gorie',
            color_discrete_sequence=px.colors.qualitative.Set3
        )
        fig_cat.update_layout(height=400)
        st.plotly_chart(fig_cat, use_container_width=True)
    
    with col2:
        # Top 10 des villes
        top_villes = df['adresse'].value_counts().head(10)
        fig_villes = px.bar(
            x=top_villes.values,
            y=top_villes.index,
            orientation='h',
            title='Top 10 des Villes',
            labels={'x': 'Nombre d\'articles', 'y': 'Ville'}
        )
        fig_villes.update_layout(height=400)
        st.plotly_chart(fig_villes, use_container_width=True)
    
    # Analyse des prix si disponible
    if 'prix_numerique' in df.columns:
        prix_valides = df.dropna(subset=['prix_numerique'])
        if not prix_valides.empty:
            col1, col2 = st.columns(2)
            
            with col1:
                # Distribution des prix par catÃ©gorie
                fig_prix = px.box(
                    prix_valides, 
                    x='categorie', 
                    y='prix_numerique',
                    title='Distribution des Prix par CatÃ©gorie'
                )
                fig_prix.update_layout(height=400)
                fig_prix.update_xaxes(tickangle=45)
                st.plotly_chart(fig_prix, use_container_width=True)
            
            with col2:
                # Histogramme des prix
                fig_hist = px.histogram(
                    prix_valides, 
                    x='prix_numerique',
                    title='Distribution des Prix',
                    nbins=30
                )
                fig_hist.update_layout(height=400)
                st.plotly_chart(fig_hist, use_container_width=True)

# Sidebar pour les paramÃ¨tres
st.sidebar.header('ğŸ”§ ParamÃ¨tres de Configuration')
st.sidebar.markdown("---")

# SÃ©lection du nombre de pages
pages = st.sidebar.selectbox(
    'ğŸ“„ Nombre de pages Ã  scraper',
    options=list(range(1, 201)),
    index=2,  # Par dÃ©faut 3 pages
    help="SÃ©lectionnez le nombre de pages Ã  scraper pour chaque catÃ©gorie"
)

# Options principales
choices = st.sidebar.selectbox(
    'ğŸ¯ Choisissez une option',
    options=[
        'Scraper avec BeautifulSoup (nettoyage)',
        'Scraper avec Web Scraper (donnÃ©es brutes)',
        'TÃ©lÃ©charger donnÃ©es prÃ©-scrapÃ©es',
        'Dashboard des donnÃ©es nettoyÃ©es',
        'Formulaire d\'Ã©valuation'
    ],
    help="SÃ©lectionnez l'action que vous souhaitez effectuer"
)

st.sidebar.markdown("---")

# Configuration des chemins pour les fichiers prÃ©-scrapÃ©s
if choices == 'TÃ©lÃ©charger donnÃ©es prÃ©-scrapÃ©es':
    st.sidebar.subheader('ğŸ“ Chemins des fichiers CSV')
    
    vetements_homme_path = st.sidebar.text_input(
        'VÃªtements Homme CSV',
        value='data/vetements_homme.csv',
        help='Chemin vers le fichier CSV des vÃªtements homme'
    )
    
    chaussures_homme_path = st.sidebar.text_input(
        'Chaussures Homme CSV',
        value='data/chaussures_homme.csv',
        help='Chemin vers le fichier CSV des chaussures homme'
    )
    
    vetements_enfants_path = st.sidebar.text_input(
        'VÃªtements Enfants CSV',
        value='data/vetements_enfants.csv',
        help='Chemin vers le fichier CSV des vÃªtements enfants'
    )
    
    chaussures_enfants_path = st.sidebar.text_input(
        'Chaussures Enfants CSV',
        value='data/chaussures_enfants.csv',
        help='Chemin vers le fichier CSV des chaussures enfants'
    )

st.sidebar.markdown("---")
st.sidebar.markdown("""
    <div style='text-align: center; color: #666; font-size: 0.8rem;'>
        <p>DÃ©veloppÃ© par Emmanuel ZAGRE</p>
        <p>Â© 2025 CoinAfrique's data Scraping and analysing</p>
    </div>
""", unsafe_allow_html=True)

# Interface principale
if choices == 'Scraper avec BeautifulSoup (nettoyage)':
    st.markdown("""
        <div style='background-color: #e8f4f8; padding: 1rem; border-radius: 10px; margin: 1rem 0;'>
            <h3 style='color: #2E86AB; margin-bottom: 1rem;'>ğŸ”„ Scraping avec BeautifulSoup et nettoyage</h3>
            <p>Cliquez sur les boutons ci-dessous pour scraper et nettoyer les donnÃ©es en temps rÃ©el depuis Coinafrique.</p>
        </div>
    """, unsafe_allow_html=True)
    
    # URLs de base pour chaque catÃ©gorie
    urls = {
        'VÃªtements Homme': 'https://sn.coinafrique.com/categorie/vetements-homme',
        'Chaussures Homme': 'https://sn.coinafrique.com/categorie/chaussures-homme',
        'VÃªtements Enfants': 'https://sn.coinafrique.com/categorie/vetements-enfants',
        'Chaussures Enfants': 'https://sn.coinafrique.com/categorie/chaussures-enfants'
    }
    
    # CrÃ©er les colonnes pour les boutons
    col1, col2 = st.columns(2)
    
    with col1:
        # VÃªtements Homme
        st.markdown("### ğŸ‘” VÃªtements Homme")
        if st.button('ğŸš€ Scraper VÃªtements Homme', key='scrape_vh', use_container_width=True):
            with st.spinner('Scraping en cours...'):
                df = scrape_with_beautifulsoup(urls['VÃªtements Homme'], 'VÃªtements Homme', pages, clean_data=True)
                if not df.empty:
                    st.success(f'âœ… {len(df)} articles rÃ©cupÃ©rÃ©s et nettoyÃ©s!')
                    st.info(f'ğŸ“Š Dimensions: {df.shape[0]} lignes et {df.shape[1]} colonnes')
                    st.dataframe(df.head(), use_container_width=True)
                    
                    # Sauvegarder automatiquement
                    if save_data_to_csv(df, 'vetements_homme_cleaned.csv'):
                        st.success('ğŸ’¾ DonnÃ©es sauvegardÃ©es dans vetements_homme_cleaned.csv')
                    
                    # Bouton de tÃ©lÃ©chargement
                    csv = convert_df_to_csv(df)
                    st.download_button(
                        label="ğŸ“¥ TÃ©lÃ©charger CSV",
                        data=csv,
                        file_name=f'vetements_homme_cleaned_{datetime.now().strftime("%Y%m%d_%H%M%S")}.csv',
                        mime='text/csv',
                        key='download_vh'
                    )
                else:
                    st.warning('âš ï¸ Aucune donnÃ©e rÃ©cupÃ©rÃ©e.')
        
        # VÃªtements Enfants
        st.markdown("### ğŸ‘¶ VÃªtements Enfants")
        if st.button('ğŸš€ Scraper VÃªtements Enfants', key='scrape_ve', use_container_width=True):
            with st.spinner('Scraping en cours...'):
                df = scrape_with_beautifulsoup(urls['VÃªtements Enfants'], 'VÃªtements Enfants', pages, clean_data=True)
                if not df.empty:
                    st.success(f'âœ… {len(df)} articles rÃ©cupÃ©rÃ©s et nettoyÃ©s!')
                    st.info(f'ğŸ“Š Dimensions: {df.shape[0]} lignes et {df.shape[1]} colonnes')
                    st.dataframe(df.head(), use_container_width=True)
                    
                    # Sauvegarder automatiquement
                    if save_data_to_csv(df, 'vetements_enfants_cleaned.csv'):
                        st.success('ğŸ’¾ DonnÃ©es sauvegardÃ©es dans vetements_enfants_cleaned.csv')
                    
                    # Bouton de tÃ©lÃ©chargement
                    csv = convert_df_to_csv(df)
                    st.download_button(
                        label="ğŸ“¥ TÃ©lÃ©charger CSV",
                        data=csv,
                        file_name=f'vetements_enfants_cleaned_{datetime.now().strftime("%Y%m%d_%H%M%S")}.csv',
                        mime='text/csv',
                        key='download_ve'
                    )
                else:
                    st.warning('âš ï¸ Aucune donnÃ©e rÃ©cupÃ©rÃ©e.')
    
    with col2:
        # Chaussures Homme
        st.markdown("### ğŸ‘ Chaussures Homme")
        if st.button('ğŸš€ Scraper Chaussures Homme', key='scrape_ch', use_container_width=True):
            with st.spinner('Scraping en cours...'):
                df = scrape_with_beautifulsoup(urls['Chaussures Homme'], 'Chaussures Homme', pages, clean_data=True)
                if not df.empty:
                    st.success(f'âœ… {len(df)} articles rÃ©cupÃ©rÃ©s et nettoyÃ©s!')
                    st.info(f'ğŸ“Š Dimensions: {df.shape[0]} lignes et {df.shape[1]} colonnes')
                    st.dataframe(df.head(), use_container_width=True)
                    
                    # Sauvegarder automatiquement
                    if save_data_to_csv(df, 'chaussures_homme_cleaned.csv'):
                        st.success('ğŸ’¾ DonnÃ©es sauvegardÃ©es dans chaussures_homme_cleaned.csv')
                    
                    # Bouton de tÃ©lÃ©chargement
                    csv = convert_df_to_csv(df)
                    st.download_button(
                        label="ğŸ“¥ TÃ©lÃ©charger CSV",
                        data=csv,
                        file_name=f'chaussures_homme_cleaned_{datetime.now().strftime("%Y%m%d_%H%M%S")}.csv',
                        mime='text/csv',
                        key='download_ch'
                    )
                else:
                    st.warning('âš ï¸ Aucune donnÃ©e rÃ©cupÃ©rÃ©e.')
        
        # Chaussures Enfants
        st.markdown("### ğŸ‘Ÿ Chaussures Enfants")
        if st.button('ğŸš€ Scraper Chaussures Enfants', key='scrape_ce', use_container_width=True):
            with st.spinner('Scraping en cours...'):
                df = scrape_with_beautifulsoup(urls['Chaussures Enfants'], 'Chaussures Enfants', pages, clean_data=True)
                if not df.empty:
                    st.success(f'âœ… {len(df)} articles rÃ©cupÃ©rÃ©s et nettoyÃ©s!')
                    st.info(f'ğŸ“Š Dimensions: {df.shape[0]} lignes et {df.shape[1]} colonnes')
                    st.dataframe(df.head(), use_container_width=True)
                    
                    # Sauvegarder automatiquement
                    if save_data_to_csv(df, 'chaussures_enfants_cleaned.csv'):
                        st.success('ğŸ’¾ DonnÃ©es sauvegardÃ©es dans chaussures_enfants_cleaned.csv')
                    
                    # Bouton de tÃ©lÃ©chargement
                    csv = convert_df_to_csv(df)
                    st.download_button(
                        label="ğŸ“¥ TÃ©lÃ©charger CSV",
                        data=csv,
                        file_name=f'chaussures_enfants_cleaned_{datetime.now().strftime("%Y%m%d_%H%M%S")}.csv',
                        mime='text/csv',
                        key='download_ce'
                    )
                else:
                    st.warning('âš ï¸ Aucune donnÃ©e rÃ©cupÃ©rÃ©e.')

elif choices == 'Scraper avec Web Scraper (donnÃ©es brutes)':
    st.markdown("""
        <div style='background-color: #fff3cd; padding: 1rem; border-radius: 10px; margin: 1rem 0;'>
            <h3 style='color: #856404; margin-bottom: 1rem;'>ğŸ”„ Scraping avec Web Scraper (donnÃ©es brutes)</h3>
            <p>Cliquez sur les boutons ci-dessous pour scraper les donnÃ©es brutes (non nettoyÃ©es) depuis Coinafrique.</p>
        </div>
    """, unsafe_allow_html=True)
    
    # URLs de base pour chaque catÃ©gorie
    urls = {
        'VÃªtements Homme': 'https://sn.coinafrique.com/categorie/vetements-homme',
        'Chaussures Homme': 'https://sn.coinafrique.com/categorie/chaussures-homme',
        'VÃªtements Enfants': 'https://sn.coinafrique.com/categorie/vetements-enfants',
        'Chaussures Enfants': 'https://sn.coinafrique.com/categorie/chaussures-enfants'
    }
    
    # CrÃ©er les colonnes pour les boutons
    col1, col2 = st.columns(2)
    
    with col1:
        # VÃªtements Homme
        st.markdown("### ğŸ‘” VÃªtements Homme")
        if st.button('ğŸš€ Scraper VÃªtements Homme (Brut)', key='scrape_vh_raw', use_container_width=True):
            with st.spinner('Scraping en cours...'):
                df = scrape_with_beautifulsoup(urls['VÃªtements Homme'], 'VÃªtements Homme', pages, clean_data=False)
                if not df.empty:
                    st.success(f'âœ… {len(df)} articles rÃ©cupÃ©rÃ©s (donnÃ©es brutes)!')
                    st.info(f'ğŸ“Š Dimensions: {df.shape[0]} lignes et {df.shape[1]} colonnes')
                    st.dataframe(df.head(), use_container_width=True)
                    
                    # Sauvegarder automatiquement
                    if save_data_to_csv(df, 'vetements_homme_raw.csv'):
                        st.success('ğŸ’¾ DonnÃ©es sauvegardÃ©es dans vetements_homme_raw.csv')
                    
                    # Bouton de tÃ©lÃ©chargement
                    csv = convert_df_to_csv(df)
                    st.download_button(
                        label="ğŸ“¥ TÃ©lÃ©charger CSV",
                        data=csv,
                        file_name=f'vetements_homme_raw_{datetime.now().strftime("%Y%m%d_%H%M%S")}.csv',
                        mime='text/csv',
                        key='download_vh_raw'
                    )
                else:
                    st.warning('âš ï¸ Aucune donnÃ©e rÃ©cupÃ©rÃ©e.')
        
        # VÃªtements Enfants
        st.markdown("### ğŸ‘¶ VÃªtements Enfants")
        if st.button('ğŸš€ Scraper VÃªtements Enfants (Brut)', key='scrape_ve_raw', use_container_width=True):
            with st.spinner('Scraping en cours...'):
                df = scrape_with_beautifulsoup(urls['VÃªtements Enfants'], 'VÃªtements Enfants', pages, clean_data=False)
                if not df.empty:
                    st.success(f'âœ… {len(df)} articles rÃ©cupÃ©rÃ©s (donnÃ©es brutes)!')
                    st.info(f'ğŸ“Š Dimensions: {df.shape[0]} lignes et {df.shape[1]} colonnes')
                    st.dataframe(df.head(), use_container_width=True)
                    
                    # Sauvegarder automatiquement
                    if save_data_to_csv(df, 'vetements_enfants_raw.csv'):
                        st.success('ğŸ’¾ DonnÃ©es sauvegardÃ©es dans vetements_enfants_raw.csv')
                    
                    # Bouton de tÃ©lÃ©chargement
                    csv = convert_df_to_csv(df)
                    st.download_button(
                        label="ğŸ“¥ TÃ©lÃ©charger CSV",
                        data=csv,
                        file_name=f'vetements_enfants_raw_{datetime.now().strftime("%Y%m%d_%H%M%S")}.csv',
                        mime='text/csv',
                        key='download_ve_raw'
                    )
                else:
                    st.warning('âš ï¸ Aucune donnÃ©e rÃ©cupÃ©rÃ©e.')
    
    with col2:
        # Chaussures Homme
        st.markdown("### ğŸ‘ Chaussures Homme")
        if st.button('ğŸš€ Scraper Chaussures Homme (Brut)', key='scrape_ch_raw', use_container_width=True):
            with st.spinner('Scraping en cours...'):
                df = scrape_with_beautifulsoup(urls['Chaussures Homme'], 'Chaussures Homme', pages, clean_data=False)
                if not df.empty:
                    st.success(f'âœ… {len(df)} articles rÃ©cupÃ©rÃ©s (donnÃ©es brutes)!')
                    st.info(f'ğŸ“Š Dimensions: {df.shape[0]} lignes et {df.shape[1]} colonnes')
                    st.dataframe(df.head(), use_container_width=True)
                    
                    # Sauvegarder automatiquement
                    if save_data_to_csv(df, 'chaussures_homme_raw.csv'):
                        st.success('ğŸ’¾ DonnÃ©es sauvegardÃ©es dans chaussures_homme_raw.csv')
                    
                    # Bouton de tÃ©lÃ©chargement
                    csv = convert_df_to_csv(df)
                    st.download_button(
                        label="ğŸ“¥ TÃ©lÃ©charger CSV",
                        data=csv,
                        file_name=f'chaussures_homme_raw_{datetime.now().strftime("%Y%m%d_%H%M%S")}.csv',
                        mime='text/csv',
                        key='download_ch_raw'
                    )
                else:
                    st.warning('âš ï¸ Aucune donnÃ©e rÃ©cupÃ©rÃ©e.')
        
        # Chaussures Enfants
        st.markdown("### ğŸ‘Ÿ Chaussures Enfants")
        if st.button('ğŸš€ Scraper Chaussures Enfants (Brut)', key='scrape_ce_raw', use_container_width=True):
            with st.spinner('Scraping en cours...'):
                df = scrape_with_beautifulsoup(urls['Chaussures Enfants'], 'Chaussures Enfants', pages, clean_data=False)
                if not df.empty:
                    st.success(f'âœ… {len(df)} articles rÃ©cupÃ©rÃ©s (donnÃ©es brutes)!')
                    st.info(f'ğŸ“Š Dimensions: {df.shape[0]} lignes et {df.shape[1]} colonnes')
                    st.dataframe(df.head(), use_container_width=True)
                    
                    # Sauvegarder automatiquement
                    if save_data_to_csv(df, 'chaussures_enfants_raw.csv'):
                        st.success('ğŸ’¾ DonnÃ©es sauvegardÃ©es dans chaussures_enfants_raw.csv')
                    
                    # Bouton de tÃ©lÃ©chargement
                    csv = convert_df_to_csv(df)
                    st.download_button(
                        label="ğŸ“¥ TÃ©lÃ©charger CSV",
                        data=csv,
                        file_name=f'chaussures_enfants_raw_{datetime.now().strftime("%Y%m%d_%H%M%S")}.csv',
                        mime='text/csv',
                        key='download_ce_raw'
                    )
                else:
                    st.warning('âš ï¸ Aucune donnÃ©e rÃ©cupÃ©rÃ©e.')

elif choices == 'TÃ©lÃ©charger donnÃ©es prÃ©-scrapÃ©es':
    st.markdown("""
        <div style='background-color: #d1ecf1; padding: 1rem; border-radius: 10px; margin: 1rem 0;'>
            <h3 style='color: #0c5460; margin-bottom: 1rem;'>ğŸ“¥ TÃ©lÃ©charger donnÃ©es prÃ©-scrapÃ©es</h3>
            <p>Chargez et tÃ©lÃ©chargez les donnÃ©es qui ont Ã©tÃ© prÃ©-scrapÃ©es et sauvegardÃ©es dans des fichiers CSV.</p>
        </div>
    """, unsafe_allow_html=True)
    
    # CrÃ©er les colonnes pour les boutons
    col1, col2 = st.columns(2)
    
    with col1:
        # VÃªtements Homme
        st.markdown("### ğŸ‘” VÃªtements Homme")
        if st.button('ğŸ“‚ Charger VÃªtements Homme', key='load_vh', use_container_width=True):
            df = load_data_from_csv(vetements_homme_path)
            if not df.empty:
                st.success(f'âœ… {len(df)} articles chargÃ©s depuis {vetements_homme_path}!')
                st.info(f'ğŸ“Š Dimensions: {df.shape[0]} lignes et {df.shape[1]} colonnes')
                st.dataframe(df.head(10), use_container_width=True)
                
                # Bouton de tÃ©lÃ©chargement
                csv = convert_df_to_csv(df)
                st.download_button(
                    label="ğŸ“¥ TÃ©lÃ©charger CSV",
                    data=csv,
                    file_name=f'vetements_homme_prescraped_{datetime.now().strftime("%Y%m%d_%H%M%S")}.csv',
                    mime='text/csv',
                    key='download_vh_pre'
                )
            else:
                st.warning('âš ï¸ Aucune donnÃ©e trouvÃ©e ou fichier inexistant.')
        
        # VÃªtements Enfants
        st.markdown("### ğŸ‘¶ VÃªtements Enfants")
        if st.button('ğŸ“‚ Charger VÃªtements Enfants', key='load_ve', use_container_width=True):
            df = load_data_from_csv(vetements_enfants_path)
            if not df.empty:
                st.success(f'âœ… {len(df)} articles chargÃ©s depuis {vetements_enfants_path}!')
                st.info(f'ğŸ“Š Dimensions: {df.shape[0]} lignes et {df.shape[1]} colonnes')
                st.dataframe(df.head(10), use_container_width=True)
                
                # Bouton de tÃ©lÃ©chargement
                csv = convert_df_to_csv(df)
                st.download_button(
                    label="ğŸ“¥ TÃ©lÃ©charger CSV",
                    data=csv,
                    file_name=f'vetements_enfants_prescraped_{datetime.now().strftime("%Y%m%d_%H%M%S")}.csv',
                    mime='text/csv',
                    key='download_ve_pre'
                )
            else:
                st.warning('âš ï¸ Aucune donnÃ©e trouvÃ©e ou fichier inexistant.')
    
    with col2:
        # Chaussures Homme
        st.markdown("### ğŸ‘ Chaussures Homme")
        if st.button('ğŸ“‚ Charger Chaussures Homme', key='load_ch', use_container_width=True):
            df = load_data_from_csv(chaussures_homme_path)
            if not df.empty:
                st.success(f'âœ… {len(df)} articles chargÃ©s depuis {chaussures_homme_path}!')
                st.info(f'ğŸ“Š Dimensions: {df.shape[0]} lignes et {df.shape[1]} colonnes')
                st.dataframe(df.head(10), use_container_width=True)
                
                # Bouton de tÃ©lÃ©chargement
                csv = convert_df_to_csv(df)
                st.download_button(
                    label="ğŸ“¥ TÃ©lÃ©charger CSV",
                    data=csv,
                    file_name=f'chaussures_homme_prescraped_{datetime.now().strftime("%Y%m%d_%H%M%S")}.csv',
                    mime='text/csv',
                    key='download_ch_pre'
                )
            else:
                st.warning('âš ï¸ Aucune donnÃ©e trouvÃ©e ou fichier inexistant.')
        
        # Chaussures Enfants
        st.markdown("### ğŸ‘Ÿ Chaussures Enfants")
        if st.button('ğŸ“‚ Charger Chaussures Enfants', key='load_ce', use_container_width=True):
            df = load_data_from_csv(chaussures_enfants_path)
            if not df.empty:
                st.success(f'âœ… {len(df)} articles chargÃ©s depuis {chaussures_enfants_path}!')
                st.info(f'ğŸ“Š Dimensions: {df.shape[0]} lignes et {df.shape[1]} colonnes')
                st.dataframe(df.head(10), use_container_width=True)
                
                # Bouton de tÃ©lÃ©chargement
                csv = convert_df_to_csv(df)
                st.download_button(
                    label="ğŸ“¥ TÃ©lÃ©charger CSV",
                    data=csv,
                    file_name=f'chaussures_enfants_prescraped_{datetime.now().strftime("%Y%m%d_%H%M%S")}.csv',
                    mime='text/csv',
                    key='download_ce_pre'
                )
            else:
                st.warning('âš ï¸ Aucune donnÃ©e trouvÃ©e ou fichier inexistant.')
    
    # Section pour charger tous les fichiers Ã  la fois
    st.markdown("---")
    st.markdown("### ğŸ“Š Charger toutes les donnÃ©es")
    
    if st.button('ğŸ“‚ Charger toutes les catÃ©gories', key='load_all', use_container_width=True):
        all_data = []
        paths = [
            (vetements_homme_path, 'VÃªtements Homme'),
            (chaussures_homme_path, 'Chaussures Homme'),
            (vetements_enfants_path, 'VÃªtements Enfants'),
            (chaussures_enfants_path, 'Chaussures Enfants')
        ]
        
        for path, category in paths:
            df = load_data_from_csv(path)
            if not df.empty:
                all_data.append(df)
                st.success(f'âœ… {category}: {len(df)} articles chargÃ©s')
            else:
                st.warning(f'âš ï¸ {category}: Aucune donnÃ©e trouvÃ©e')
        
        if all_data:
            combined_df = pd.concat(all_data, ignore_index=True)
            st.success(f'ğŸ‰ Total combinÃ©: {len(combined_df)} articles de {len(all_data)} catÃ©gories')
            st.dataframe(combined_df.head(20), use_container_width=True)
            
            # Bouton de tÃ©lÃ©chargement pour toutes les donnÃ©es
            csv_all = convert_df_to_csv(combined_df)
            st.download_button(
                label="ğŸ“¥ TÃ©lÃ©charger toutes les donnÃ©es (CSV)",
                data=csv_all,
                file_name=f'coinafrique_all_data_{datetime.now().strftime("%Y%m%d_%H%M%S")}.csv',
                mime='text/csv',
                key='download_all_pre'
            )

elif choices == 'Dashboard des donnÃ©es nettoyÃ©es':
    st.markdown("""
        <div style='background-color: #d4edda; padding: 1rem; border-radius: 10px; margin: 1rem 0;'>
            <h3 style='color: #155724; margin-bottom: 1rem;'>ğŸ“Š Dashboard des donnÃ©es nettoyÃ©es</h3>
            <p>Visualisez les donnÃ©es nettoyÃ©es sous forme de graphiques interactifs.</p>
        </div>
    """, unsafe_allow_html=True)
    
    # Option pour choisir la source des donnÃ©es
    data_source = st.selectbox(
        'ğŸ“‚ Choisir la source des donnÃ©es',
        options=[
            'Charger depuis fichiers CSV',
            'Utiliser donnÃ©es d\'exemple',
            'Combiner toutes les sources'
        ],
        help="SÃ©lectionnez la source des donnÃ©es pour le dashboard"
    )
    
    if data_source == 'Charger depuis fichiers CSV':
        st.markdown("### ğŸ“ SÃ©lectionner les fichiers Ã  analyser")
        
        # Checkboxes pour sÃ©lectionner les fichiers
        use_vh = st.checkbox('VÃªtements Homme', value=True)
        use_ch = st.checkbox('Chaussures Homme', value=True)
        use_ve = st.checkbox('VÃªtements Enfants', value=True)
        use_ce = st.checkbox('Chaussures Enfants', value=True)
        
        if st.button('ğŸš€ GÃ©nÃ©rer Dashboard', key='generate_dashboard'):
            dashboard_data = []
            
            if use_vh:
                df_vh = load_data_from_csv('data/vetements_homme.csv')
                if not df_vh.empty:
                    dashboard_data.append(df_vh)
            
            if use_ch:
                df_ch = load_data_from_csv('data/chaussures_homme.csv')
                if not df_ch.empty:
                    dashboard_data.append(df_ch)
            
            if use_ve:
                df_ve = load_data_from_csv('data/vetements_enfants.csv')
                if not df_ve.empty:
                    dashboard_data.append(df_ve)
            
            if use_ce:
                df_ce = load_data_from_csv('data/chaussures_enfants.csv')
                if not df_ce.empty:
                    dashboard_data.append(df_ce)
            
            if dashboard_data:
                combined_df = pd.concat(dashboard_data, ignore_index=True)
                # Nettoyer les donnÃ©es avant de crÃ©er le dashboard
                cleaned_df = clean_scraped_data(combined_df)
                create_dashboard(cleaned_df)
            else:
                st.warning('âš ï¸ Aucune donnÃ©e trouvÃ©e dans les fichiers sÃ©lectionnÃ©s.')
    
    elif data_source == 'Utiliser donnÃ©es d\'exemple':
        # CrÃ©er des donnÃ©es d'exemple rÃ©alistes
        sample_data = pd.DataFrame({
            'categorie': ['VÃªtements Homme', 'Chaussures Homme', 'VÃªtements Enfants', 'Chaussures Enfants'] * 50,
            'type': ['Chemise', 'Sneakers', 'T-shirt', 'Sandales'] * 50,
            'prix': ['15000 FCFA', '25000 FCFA', '8000 FCFA', '12000 FCFA'] * 50,
            'adresse': ['Dakar', 'ThiÃ¨s', 'Kaolack', 'Saint-Louis', 'Ziguinchor'] * 40,
            'image_lien': ['https://example.com/img1.jpg'] * 200
        })
        
        # Ajouter de la variabilitÃ©
        np.random.seed(42)
        prix_variations = np.random.normal(1, 0.3, len(sample_data))
        sample_data['prix'] = sample_data['prix'].str.replace(r'[^\d]', '', regex=True).astype(int)
        sample_data['prix'] = (sample_data['prix'] * prix_variations).astype(int)
        sample_data['prix'] = sample_data['prix'].astype(str) + ' FCFA'
        
        cleaned_sample = clean_scraped_data(sample_data)
        create_dashboard(cleaned_sample)
    
    else:  # Combiner toutes les sources
        st.markdown("### ğŸ“Š Dashboard combinÃ©")
        if st.button('ğŸš€ GÃ©nÃ©rer Dashboard Complet', key='generate_full_dashboard'):
            # Essayer de charger toutes les donnÃ©es disponibles
            all_sources = []
            
            # Fichiers possibles
            possible_files = [
                ('data/vetements_homme.csv', 'VÃªtements Homme'),
                ('data/chaussures_homme.csv', 'Chaussures Homme'),
                ('data/vetements_enfants.csv', 'VÃªtements Enfants'),
                ('data/chaussures_enfants.csv', 'Chaussures Enfants'),
                ('vetements_homme_cleaned.csv', 'VÃªtements Homme (NettoyÃ©es)'),
                ('chaussures_homme_cleaned.csv', 'Chaussures Homme (NettoyÃ©es)'),
                ('vetements_enfants_cleaned.csv', 'VÃªtements Enfants (NettoyÃ©es)'),
                ('chaussures_enfants_cleaned.csv', 'Chaussures Enfants (NettoyÃ©es)')
            ]
            
            for filepath, category in possible_files:
                df = load_data_from_csv(filepath)
                if not df.empty:
                    all_sources.append(df)
                    st.info(f'âœ… {category}: {len(df)} articles chargÃ©s')
            
            if all_sources:
                combined_df = pd.concat(all_sources, ignore_index=True)
                # Supprimer les doublons
                combined_df = combined_df.drop_duplicates()
                cleaned_combined = clean_scraped_data(combined_df)
                
                st.success(f'ğŸ‰ Dashboard gÃ©nÃ©rÃ© avec {len(cleaned_combined)} articles uniques')
                create_dashboard(cleaned_combined)
            else:
                st.warning('âš ï¸ Aucune donnÃ©e trouvÃ©e. Veuillez d\'abord scraper des donnÃ©es.')

else:  # Formulaire d'Ã©valuation
    st.markdown("""
        <div style='background-color: #f8d7da; padding: 1rem; border-radius: 10px; margin: 1rem 0;'>
            <h3 style='color: #721c24; margin-bottom: 1rem;'>ğŸ“ Formulaire d'Ã©valuation</h3>
            <p>Donnez votre avis sur cette application via KoboToolbox.</p>
        </div>
    """, unsafe_allow_html=True)
    
    # Section d'Ã©valuation locale
    st.markdown("### ğŸŒŸ Ã‰valuation rapide")
    
    col1, col2 = st.columns(2)
    
    with col1:
        # Formulaire d'Ã©valuation local
        with st.form("evaluation_form"):
            st.markdown("**Ã‰valuez l'application :**")
            
            note_generale = st.slider("Note gÃ©nÃ©rale", 1, 5, 4)
            facilite_utilisation = st.slider("FacilitÃ© d'utilisation", 1, 5, 4)
            qualite_donnees = st.slider("QualitÃ© des donnÃ©es", 1, 5, 4)
            vitesse_scraping = st.slider("Vitesse de scraping", 1, 5, 3)
            
            fonctionnalites = st.multiselect(
                "FonctionnalitÃ©s les plus utiles",
                ["Scraping BeautifulSoup", "Scraping Web Scraper", "Dashboard", "TÃ©lÃ©chargement CSV", "Interface utilisateur"]
            )
            
            commentaires = st.text_area("Commentaires et suggestions")
            
            submitted = st.form_submit_button("ğŸ“¤ Soumettre l'Ã©valuation")
            
            if submitted:
                st.success("âœ… Merci pour votre Ã©valuation!")
                
                # Afficher un rÃ©sumÃ©
                st.markdown("### ğŸ“Š RÃ©sumÃ© de votre Ã©valuation")
                st.write(f"**Note gÃ©nÃ©rale:** {note_generale}/5")
                st.write(f"**FacilitÃ© d'utilisation:** {facilite_utilisation}/5")
                st.write(f"**QualitÃ© des donnÃ©es:** {qualite_donnees}/5")
                st.write(f"**Vitesse de scraping:** {vitesse_scraping}/5")
                
                if fonctionnalites:
                    st.write(f"**FonctionnalitÃ©s prÃ©fÃ©rÃ©es:** {', '.join(fonctionnalites)}")
                
                if commentaires:
                    st.write(f"**Commentaires:** {commentaires}")
    
    with col2:
        # Statistiques d'utilisation simulÃ©es
        st.markdown("### ğŸ“ˆ Statistiques d'utilisation")
        
        stats_df = pd.DataFrame({
            'FonctionnalitÃ©': ['Scraping BS4', 'Scraping Web', 'Dashboard', 'TÃ©lÃ©chargement', 'Ã‰valuation'],
            'Utilisations': [150, 120, 200, 180, 45],
            'Satisfaction': [4.2, 3.8, 4.5, 4.1, 4.3]
        })
        
        # Graphique des utilisations
        fig_usage = px.bar(stats_df, x='FonctionnalitÃ©', y='Utilisations', title='Nombre d\'utilisations par fonctionnalitÃ©')
        st.plotly_chart(fig_usage, use_container_width=True)
        
        # Graphique de satisfaction
        fig_satisfaction = px.bar(stats_df, x='FonctionnalitÃ©', y='Satisfaction', title='Satisfaction par fonctionnalitÃ©')
        st.plotly_chart(fig_satisfaction, use_container_width=True)
    
    # IntÃ©grer le formulaire KoboToolbox
    st.markdown("---")
    st.markdown("### ğŸŒ Formulaire KoboToolbox")
    
    components.html("""
        <div style='text-align: center; margin: 2rem 0;'>
            <h4>Ã‰valuez cette application sur KoboToolbox</h4>
            <p>Votre feedback dÃ©taillÃ© nous aide Ã  amÃ©liorer l'application.</p>
            <iframe src=https://ee.kobotoolbox.org/i/NN2REojo width="800" height="600"></iframe>
        </div>
    """, height=650)

# Footer
st.markdown("---")
st.markdown("""
    <div style='text-align: center; padding: 2rem; margin-top: 3rem; border-top: 1px solid #ddd;'>
        <p style='color: #666; margin: 0;'>
            ğŸš€ Coinafrique Scraper - DÃ©veloppÃ© avec Streamlit et BeautifulSoup
        </p>
        <p style='color: #999; font-size: 0.8rem; margin: 0.5rem 0 0 0;'>
            Scraping BeautifulSoup (nettoyage) | Web Scraper (donnÃ©es brutes) | Dashboard interactif | Ã‰valuation
        </p>
        <p style='color: #999; font-size: 0.8rem; margin: 0.5rem 0 0 0;'>
            Pour toute question ou suggestion, contactez l'Ã©quipe de dÃ©veloppement
        </p>
    </div>
""", unsafe_allow_html=True)
